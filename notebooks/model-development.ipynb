{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data handling and ML imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import classification_report, make_scorer, accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "# MLflow and DagsHub imports\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "import mlflow.xgboost\n",
        "import mlflow.lightgbm\n",
        "import dagshub\n",
        "\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load Processed Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MLflow and DagsHub Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"fasnis/fiap-ds-mlops-10dtsr-creditscoring-grupo7\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Initialized MLflow to track repo \u001b[32m\"fasnis/fiap-ds-mlops-10dtsr-creditscoring-grupo7\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository fasnis/fiap-ds-mlops-10dtsr-creditscoring-grupo7 initialized!\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Repository fasnis/fiap-ds-mlops-10dtsr-creditscoring-grupo7 initialized!\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/08/03 00:59:46 INFO mlflow.tracking.fluent: Autologging successfully enabled for lightgbm.\n",
            "2025/08/03 00:59:46 WARNING mlflow.utils.autologging_utils: MLflow sklearn autologging is known to be compatible with 1.3.0 <= scikit-learn <= 1.7.0, but the installed version is 1.7.1. If you encounter errors during autologging, try upgrading / downgrading scikit-learn to a compatible version, or try upgrading MLflow.\n",
            "2025/08/03 00:59:46 WARNING mlflow.utils.autologging_utils: MLflow sklearn autologging is known to be compatible with 1.3.0 <= scikit-learn <= 1.7.0, but the installed version is 1.7.1. If you encounter errors during autologging, try upgrading / downgrading scikit-learn to a compatible version, or try upgrading MLflow.\n",
            "2025/08/03 00:59:46 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
            "2025/08/03 00:59:46 WARNING mlflow.utils.autologging_utils: MLflow xgboost autologging is known to be compatible with 1.7.6 <= xgboost <= 3.0.2, but the installed version is 3.0.3. If you encounter errors during autologging, try upgrading / downgrading xgboost to a compatible version, or try upgrading MLflow.\n",
            "2025/08/03 00:59:46 INFO mlflow.tracking.fluent: Autologging successfully enabled for xgboost.\n",
            "2025/08/03 00:59:46 WARNING mlflow.spark: With Pyspark >= 3.2, PYSPARK_PIN_THREAD environment variable must be set to false for Spark datasource autologging to work.\n",
            "2025/08/03 00:59:46 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.\n",
            "2025/08/03 00:59:46 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
            "2025/08/03 00:59:46 WARNING mlflow.utils.autologging_utils: MLflow xgboost autologging is known to be compatible with 1.7.6 <= xgboost <= 3.0.2, but the installed version is 3.0.3. If you encounter errors during autologging, try upgrading / downgrading xgboost to a compatible version, or try upgrading MLflow.\n",
            "2025/08/03 00:59:46 INFO mlflow.tracking.fluent: Autologging successfully enabled for xgboost.\n",
            "2025/08/03 00:59:46 WARNING mlflow.spark: With Pyspark >= 3.2, PYSPARK_PIN_THREAD environment variable must be set to false for Spark datasource autologging to work.\n",
            "2025/08/03 00:59:46 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.\n",
            "2025/08/03 00:59:46 INFO mlflow.pyspark.ml: No SparkSession detected. Autologging will log pyspark.ml models contained in the default allowlist. To specify a custom allowlist, initialize a SparkSession prior to calling mlflow.pyspark.ml.autolog() and specify the path to your allowlist file via the spark.mlflow.pysparkml.autolog.logModelAllowlistFile conf.\n",
            "2025/08/03 00:59:46 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.ml.\n",
            "2025/08/03 00:59:46 INFO mlflow.pyspark.ml: No SparkSession detected. Autologging will log pyspark.ml models contained in the default allowlist. To specify a custom allowlist, initialize a SparkSession prior to calling mlflow.pyspark.ml.autolog() and specify the path to your allowlist file via the spark.mlflow.pysparkml.autolog.logModelAllowlistFile conf.\n",
            "2025/08/03 00:59:46 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.ml.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MLflow tracking initialized successfully\n"
          ]
        }
      ],
      "source": [
        "# Initialize DagsHub connection and MLflow tracking\n",
        "dagshub.init(repo_owner=\"fasnis\", repo_name=\"fiap-ds-mlops-10dtsr-creditscoring-grupo7\", mlflow=True)\n",
        "\n",
        "# Enable MLflow autologging\n",
        "mlflow.autolog()\n",
        "\n",
        "print(\"MLflow tracking initialized successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset shape: (100000, 44)\n",
            "\n",
            "Dataset info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100000 entries, 0 to 99999\n",
            "Data columns (total 44 columns):\n",
            " #   Column                                              Non-Null Count   Dtype  \n",
            "---  ------                                              --------------   -----  \n",
            " 0   ID                                                  100000 non-null  object \n",
            " 1   Customer_ID                                         100000 non-null  object \n",
            " 2   Age                                                 97224 non-null   float64\n",
            " 3   Annual_Income                                       100000 non-null  float64\n",
            " 4   Monthly_Inhand_Salary                               100000 non-null  float64\n",
            " 5   Num_Bank_Accounts                                   100000 non-null  int64  \n",
            " 6   Num_Credit_Card                                     100000 non-null  int64  \n",
            " 7   Interest_Rate                                       100000 non-null  int64  \n",
            " 8   Num_of_Loan                                         100000 non-null  int64  \n",
            " 9   Delay_from_due_date                                 100000 non-null  int64  \n",
            " 10  Num_of_Delayed_Payment                              92998 non-null   float64\n",
            " 11  Changed_Credit_Limit                                97909 non-null   float64\n",
            " 12  Num_Credit_Inquiries                                98035 non-null   float64\n",
            " 13  Outstanding_Debt                                    100000 non-null  object \n",
            " 14  Credit_Utilization_Ratio                            100000 non-null  float64\n",
            " 15  Total_EMI_per_month                                 100000 non-null  float64\n",
            " 16  Amount_invested_monthly                             95521 non-null   float64\n",
            " 17  Monthly_Balance                                     98800 non-null   float64\n",
            " 18  Credit_Score                                        100000 non-null  object \n",
            " 19  Credit_History_Age_Months                           90970 non-null   float64\n",
            " 20  Occupation_idx                                      100000 non-null  int64  \n",
            " 21  Type_of_Loan_idx                                    100000 non-null  int64  \n",
            " 22  Credit_Mix_Bad                                      100000 non-null  bool   \n",
            " 23  Credit_Mix_Good                                     100000 non-null  bool   \n",
            " 24  Credit_Mix_N/A                                      100000 non-null  bool   \n",
            " 25  Credit_Mix_Standard                                 100000 non-null  bool   \n",
            " 26  Payment_of_Min_Amount_NM                            100000 non-null  bool   \n",
            " 27  Payment_of_Min_Amount_No                            100000 non-null  bool   \n",
            " 28  Payment_of_Min_Amount_Yes                           100000 non-null  bool   \n",
            " 29  Payment_Behaviour_High_spent_Large_value_payments   100000 non-null  bool   \n",
            " 30  Payment_Behaviour_High_spent_Medium_value_payments  100000 non-null  bool   \n",
            " 31  Payment_Behaviour_High_spent_Small_value_payments   100000 non-null  bool   \n",
            " 32  Payment_Behaviour_Low_spent_Large_value_payments    100000 non-null  bool   \n",
            " 33  Payment_Behaviour_Low_spent_Medium_value_payments   100000 non-null  bool   \n",
            " 34  Payment_Behaviour_Low_spent_Small_value_payments    100000 non-null  bool   \n",
            " 35  Payment_Behaviour_N/A                               100000 non-null  bool   \n",
            " 36  Month_April                                         100000 non-null  bool   \n",
            " 37  Month_August                                        100000 non-null  bool   \n",
            " 38  Month_February                                      100000 non-null  bool   \n",
            " 39  Month_January                                       100000 non-null  bool   \n",
            " 40  Month_July                                          100000 non-null  bool   \n",
            " 41  Month_June                                          100000 non-null  bool   \n",
            " 42  Month_March                                         100000 non-null  bool   \n",
            " 43  Month_May                                           100000 non-null  bool   \n",
            "dtypes: bool(22), float64(11), int64(7), object(4)\n",
            "memory usage: 18.9+ MB\n"
          ]
        }
      ],
      "source": [
        "# Read the processed dataset from local file\n",
        "df_processed = pd.read_csv('../data/processed/creditscore_data_processed.csv')\n",
        "print(\"Dataset shape:\", df_processed.shape)\n",
        "print(\"\\nDataset info:\")\n",
        "df_processed.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adEubURa0-3R"
      },
      "source": [
        "# Machine Learning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LR2_ll40Gj0n"
      },
      "source": [
        "Agora, após fazer uma análise exploratória dos dados e transformá-los conforme necessidade, podemos ir para os modelos de classificação.\n",
        "Vamos trabalhar com três: RandomForest, XGBoost, LightGBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAvXu0nC-Dvm",
        "outputId": "e069ce0d-d971-46b4-f85e-383a6541f8b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training RandomForest...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/08/03 01:06:56 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during sklearn autologging: INTERNAL_ERROR: Response: {'error': 'unsupported endpoint, please contact support@dagshub.com'}\n",
            "2025/08/03 01:07:24 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "2025/08/03 01:07:24 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🏃 View run RandomForest at: https://dagshub.com/fasnis/fiap-ds-mlops-10dtsr-creditscoring-grupo7.mlflow/#/experiments/0/runs/a13ee505b22c465692bf84015c11e31a\n",
            "🧪 View experiment at: https://dagshub.com/fasnis/fiap-ds-mlops-10dtsr-creditscoring-grupo7.mlflow/#/experiments/0\n"
          ]
        },
        {
          "ename": "RestException",
          "evalue": "INTERNAL_ERROR: Response: {'error': 'unsupported endpoint, please contact support@dagshub.com'}",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mRestException\u001b[39m                             Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 100\u001b[39m\n\u001b[32m     97\u001b[39m mlflow.log_params(best_params)\n\u001b[32m     99\u001b[39m \u001b[38;5;66;03m# Evaluate and log the model\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m \u001b[43mevaluate_and_log_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrid_search\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbest_estimator_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_test_scaled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabel_encoder\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTraining time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mduration\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m seconds\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    109\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBest parameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgrid_search.best_params_\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mevaluate_and_log_model\u001b[39m\u001b[34m(model_name, model, X_test, y_test, label_encoder)\u001b[39m\n\u001b[32m     25\u001b[39m     mlflow.lightgbm.log_model(model, model_name)\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     \u001b[43mmlflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43msklearn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# Print classification report\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mClassification Report for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-Personal/Educação/FIAP/MBA - DATA SCIENCE AI/MLOPS/TrabalhoIntegrado/fiap-ds-mlops-10dtsr-creditscoring-grupo7/.venv/lib/python3.13/site-packages/mlflow/sklearn/__init__.py:426\u001b[39m, in \u001b[36mlog_model\u001b[39m\u001b[34m(sk_model, artifact_path, conda_env, code_paths, serialization_format, registered_model_name, signature, input_example, await_registration_for, pip_requirements, extra_pip_requirements, pyfunc_predict_fn, metadata, params, tags, model_type, step, model_id, name)\u001b[39m\n\u001b[32m    334\u001b[39m \u001b[38;5;129m@format_docstring\u001b[39m(LOG_MODEL_PARAM_DOCS.format(package_name=\u001b[33m\"\u001b[39m\u001b[33mscikit-learn\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m    335\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlog_model\u001b[39m(\n\u001b[32m    336\u001b[39m     sk_model,\n\u001b[32m   (...)\u001b[39m\u001b[32m    355\u001b[39m     name: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    356\u001b[39m ):\n\u001b[32m    357\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    358\u001b[39m \u001b[33;03m    Log a scikit-learn model as an MLflow artifact for the current run. Produces an MLflow Model\u001b[39;00m\n\u001b[32m    359\u001b[39m \u001b[33;03m    containing the following flavors:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    424\u001b[39m \n\u001b[32m    425\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m426\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mModel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    427\u001b[39m \u001b[43m        \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    428\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    429\u001b[39m \u001b[43m        \u001b[49m\u001b[43mflavor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmlflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43msklearn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    430\u001b[39m \u001b[43m        \u001b[49m\u001b[43msk_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43msk_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    431\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconda_env\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconda_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    432\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcode_paths\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcode_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    433\u001b[39m \u001b[43m        \u001b[49m\u001b[43mserialization_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserialization_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[43m        \u001b[49m\u001b[43mregistered_model_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mregistered_model_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    435\u001b[39m \u001b[43m        \u001b[49m\u001b[43msignature\u001b[49m\u001b[43m=\u001b[49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    436\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_example\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_example\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    437\u001b[39m \u001b[43m        \u001b[49m\u001b[43mawait_registration_for\u001b[49m\u001b[43m=\u001b[49m\u001b[43mawait_registration_for\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    438\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpip_requirements\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpip_requirements\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    439\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_pip_requirements\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_pip_requirements\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    440\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpyfunc_predict_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpyfunc_predict_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    441\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    442\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    443\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    444\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    445\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    446\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    447\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-Personal/Educação/FIAP/MBA - DATA SCIENCE AI/MLOPS/TrabalhoIntegrado/fiap-ds-mlops-10dtsr-creditscoring-grupo7/.venv/lib/python3.13/site-packages/mlflow/models/model.py:1161\u001b[39m, in \u001b[36mModel.log\u001b[39m\u001b[34m(cls, artifact_path, flavor, registered_model_name, await_registration_for, metadata, run_id, resources, auth_policy, prompts, name, model_type, params, tags, step, model_id, **kwargs)\u001b[39m\n\u001b[32m   1156\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1157\u001b[39m     params = {\n\u001b[32m   1158\u001b[39m         **(params \u001b[38;5;129;01mor\u001b[39;00m {}),\n\u001b[32m   1159\u001b[39m         **(client.get_run(run_id).data.params \u001b[38;5;28;01mif\u001b[39;00m run_id \u001b[38;5;28;01melse\u001b[39;00m {}),\n\u001b[32m   1160\u001b[39m     }\n\u001b[32m-> \u001b[39m\u001b[32m1161\u001b[39m     model = \u001b[43mmlflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43minitialize_logged_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1162\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# TODO: Update model name\u001b[39;49;00m\n\u001b[32m   1163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1164\u001b[39m \u001b[43m        \u001b[49m\u001b[43msource_run_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1165\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1166\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1167\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m   1168\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[32m   1169\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1170\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1171\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   1172\u001b[39m         MLFLOW_PRINT_MODEL_URLS_ON_CREATION.get()\n\u001b[32m   1173\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m is_databricks_uri(tracking_uri)\n\u001b[32m   1174\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m (workspace_url := get_workspace_url())\n\u001b[32m   1175\u001b[39m     ):\n\u001b[32m   1176\u001b[39m         logged_model_url = _construct_databricks_logged_model_url(\n\u001b[32m   1177\u001b[39m             workspace_url,\n\u001b[32m   1178\u001b[39m             model.experiment_id,\n\u001b[32m   1179\u001b[39m             model.model_id,\n\u001b[32m   1180\u001b[39m             get_workspace_id(),\n\u001b[32m   1181\u001b[39m         )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-Personal/Educação/FIAP/MBA - DATA SCIENCE AI/MLOPS/TrabalhoIntegrado/fiap-ds-mlops-10dtsr-creditscoring-grupo7/.venv/lib/python3.13/site-packages/mlflow/tracking/fluent.py:2130\u001b[39m, in \u001b[36minitialize_logged_model\u001b[39m\u001b[34m(name, source_run_id, tags, params, model_type, experiment_id)\u001b[39m\n\u001b[32m   2104\u001b[39m \u001b[38;5;129m@experimental\u001b[39m\n\u001b[32m   2105\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minitialize_logged_model\u001b[39m(\n\u001b[32m   2106\u001b[39m     name: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2111\u001b[39m     experiment_id: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   2112\u001b[39m ) -> LoggedModel:\n\u001b[32m   2113\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2114\u001b[39m \u001b[33;03m    Initialize a LoggedModel. Creates a LoggedModel with status ``PENDING`` and no artifacts. You\u001b[39;00m\n\u001b[32m   2115\u001b[39m \u001b[33;03m    must add artifacts to the model and finalize it to the ``READY`` state, for example by calling\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2128\u001b[39m \u001b[33;03m        A new :py:class:`mlflow.entities.LoggedModel` object with status ``PENDING``.\u001b[39;00m\n\u001b[32m   2129\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2130\u001b[39m     model = \u001b[43m_create_logged_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2131\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2132\u001b[39m \u001b[43m        \u001b[49m\u001b[43msource_run_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43msource_run_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2133\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2134\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2135\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2136\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexperiment_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexperiment_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2137\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2138\u001b[39m     _last_logged_model_id.set(model.model_id)\n\u001b[32m   2139\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-Personal/Educação/FIAP/MBA - DATA SCIENCE AI/MLOPS/TrabalhoIntegrado/fiap-ds-mlops-10dtsr-creditscoring-grupo7/.venv/lib/python3.13/site-packages/mlflow/tracking/fluent.py:2257\u001b[39m, in \u001b[36m_create_logged_model\u001b[39m\u001b[34m(name, source_run_id, tags, params, model_type, experiment_id)\u001b[39m\n\u001b[32m   2253\u001b[39m     experiment_id = _get_experiment_id() \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   2254\u001b[39m         get_run(source_run_id).info.experiment_id \u001b[38;5;28;01mif\u001b[39;00m source_run_id \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2255\u001b[39m     )\n\u001b[32m   2256\u001b[39m resolved_tags = context_registry.resolve_tags(tags)\n\u001b[32m-> \u001b[39m\u001b[32m2257\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mMlflowClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_logged_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2258\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexperiment_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexperiment_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2259\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2260\u001b[39m \u001b[43m    \u001b[49m\u001b[43msource_run_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43msource_run_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2261\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresolved_tags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2262\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2263\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2264\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-Personal/Educação/FIAP/MBA - DATA SCIENCE AI/MLOPS/TrabalhoIntegrado/fiap-ds-mlops-10dtsr-creditscoring-grupo7/.venv/lib/python3.13/site-packages/mlflow/tracking/client.py:5369\u001b[39m, in \u001b[36mMlflowClient.create_logged_model\u001b[39m\u001b[34m(self, experiment_id, name, source_run_id, tags, params, model_type)\u001b[39m\n\u001b[32m   5342\u001b[39m \u001b[38;5;129m@experimental\u001b[39m\n\u001b[32m   5343\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate_logged_model\u001b[39m(\n\u001b[32m   5344\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5350\u001b[39m     model_type: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   5351\u001b[39m ) -> LoggedModel:\n\u001b[32m   5352\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   5353\u001b[39m \u001b[33;03m    Create a new logged model.\u001b[39;00m\n\u001b[32m   5354\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   5367\u001b[39m \u001b[33;03m        The created model.\u001b[39;00m\n\u001b[32m   5368\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m5369\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_tracking_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_logged_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5370\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexperiment_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource_run_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_type\u001b[49m\n\u001b[32m   5371\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-Personal/Educação/FIAP/MBA - DATA SCIENCE AI/MLOPS/TrabalhoIntegrado/fiap-ds-mlops-10dtsr-creditscoring-grupo7/.venv/lib/python3.13/site-packages/mlflow/tracking/_tracking_service/client.py:824\u001b[39m, in \u001b[36mTrackingServiceClient.create_logged_model\u001b[39m\u001b[34m(self, experiment_id, name, source_run_id, tags, params, model_type)\u001b[39m\n\u001b[32m    815\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate_logged_model\u001b[39m(\n\u001b[32m    816\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    817\u001b[39m     experiment_id: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    822\u001b[39m     model_type: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    823\u001b[39m ) -> LoggedModel:\n\u001b[32m--> \u001b[39m\u001b[32m824\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstore\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_logged_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexperiment_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexperiment_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    827\u001b[39m \u001b[43m        \u001b[49m\u001b[43msource_run_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43msource_run_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    828\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mLoggedModelTag\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    829\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[32m    830\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    831\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mLoggedModelParameter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    832\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[32m    833\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    834\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    835\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-Personal/Educação/FIAP/MBA - DATA SCIENCE AI/MLOPS/TrabalhoIntegrado/fiap-ds-mlops-10dtsr-creditscoring-grupo7/.venv/lib/python3.13/site-packages/mlflow/store/tracking/rest_store.py:936\u001b[39m, in \u001b[36mRestStore.create_logged_model\u001b[39m\u001b[34m(self, experiment_id, name, source_run_id, tags, params, model_type)\u001b[39m\n\u001b[32m    923\u001b[39m     remaining_params = params[initial_batch_size:]\n\u001b[32m    925\u001b[39m req_body = message_to_json(\n\u001b[32m    926\u001b[39m     CreateLoggedModel(\n\u001b[32m    927\u001b[39m         experiment_id=experiment_id,\n\u001b[32m   (...)\u001b[39m\u001b[32m    933\u001b[39m     )\n\u001b[32m    934\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m936\u001b[39m response_proto = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCreateLoggedModel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq_body\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    937\u001b[39m model = LoggedModel.from_proto(response_proto.model)\n\u001b[32m    939\u001b[39m \u001b[38;5;66;03m# Log remaining params if there are any\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-Personal/Educação/FIAP/MBA - DATA SCIENCE AI/MLOPS/TrabalhoIntegrado/fiap-ds-mlops-10dtsr-creditscoring-grupo7/.venv/lib/python3.13/site-packages/mlflow/store/tracking/rest_store.py:135\u001b[39m, in \u001b[36mRestStore._call_endpoint\u001b[39m\u001b[34m(self, api, json_body, endpoint, retry_timeout_seconds)\u001b[39m\n\u001b[32m    133\u001b[39m     endpoint, method = _METHOD_TO_INFO[api]\n\u001b[32m    134\u001b[39m response_proto = api.Response()\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_endpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_host_creds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjson_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_proto\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry_timeout_seconds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_timeout_seconds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-Personal/Educação/FIAP/MBA - DATA SCIENCE AI/MLOPS/TrabalhoIntegrado/fiap-ds-mlops-10dtsr-creditscoring-grupo7/.venv/lib/python3.13/site-packages/mlflow/utils/rest_utils.py:594\u001b[39m, in \u001b[36mcall_endpoint\u001b[39m\u001b[34m(host_creds, endpoint, method, json_body, response_proto, extra_headers, retry_timeout_seconds)\u001b[39m\n\u001b[32m    591\u001b[39m     call_kwargs[\u001b[33m\"\u001b[39m\u001b[33mjson\u001b[39m\u001b[33m\"\u001b[39m] = json_body\n\u001b[32m    592\u001b[39m     response = http_request(**call_kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m594\u001b[39m response = \u001b[43mverify_rest_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    595\u001b[39m response_to_parse = response.text\n\u001b[32m    596\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-Personal/Educação/FIAP/MBA - DATA SCIENCE AI/MLOPS/TrabalhoIntegrado/fiap-ds-mlops-10dtsr-creditscoring-grupo7/.venv/lib/python3.13/site-packages/mlflow/utils/rest_utils.py:308\u001b[39m, in \u001b[36mverify_rest_response\u001b[39m\u001b[34m(response, endpoint)\u001b[39m\n\u001b[32m    306\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response.status_code != \u001b[32m200\u001b[39m:\n\u001b[32m    307\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _can_parse_as_json_object(response.text):\n\u001b[32m--> \u001b[39m\u001b[32m308\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m RestException(json.loads(response.text))\n\u001b[32m    309\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    310\u001b[39m         base_msg = (\n\u001b[32m    311\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAPI request to endpoint \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mendpoint\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    312\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mfailed with error code \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m != 200\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    313\u001b[39m         )\n",
            "\u001b[31mRestException\u001b[39m: INTERNAL_ERROR: Response: {'error': 'unsupported endpoint, please contact support@dagshub.com'}"
          ]
        }
      ],
      "source": [
        "# Prepare the data\n",
        "X = df_processed.drop(columns=[\"Credit_Score\"])\n",
        "\n",
        "# Convert hexadecimal strings to decimal numbers if any exist\n",
        "for col in X.columns:\n",
        "    if X[col].dtype == 'object':\n",
        "        try:\n",
        "            # Try to convert hex strings to decimal numbers\n",
        "            X[col] = X[col].apply(lambda x: float(int(str(x), 16)) if isinstance(x, str) and '0x' in str(x).lower() else x)\n",
        "        except:\n",
        "            pass  # If conversion fails, leave as is\n",
        "            \n",
        "# Convert remaining strings to numeric, coercing errors to NaN\n",
        "X = X.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# Fill NaN values with 0\n",
        "X = X.fillna(0)\n",
        "\n",
        "# Prepare target variable\n",
        "y = df_processed[\"Credit_Score\"]\n",
        "\n",
        "# Encode the target variable\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, stratify=y_encoded, random_state=42)\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Define models with their parameters\n",
        "models = {\n",
        "    \"RandomForest\": {\n",
        "        \"model\": RandomForestClassifier(random_state=42),\n",
        "        \"params\": {\n",
        "            \"n_estimators\": [100, 200],\n",
        "            \"max_depth\": [None, 10],\n",
        "            \"min_samples_split\": [2, 5]\n",
        "        }\n",
        "    },\n",
        "    \"XGBoost\": {\n",
        "        \"model\": XGBClassifier(eval_metric='mlogloss', random_state=42),\n",
        "        \"params\": {\n",
        "            \"n_estimators\": [100, 200],\n",
        "            \"max_depth\": [3, 6],\n",
        "            \"learning_rate\": [0.1, 0.3]\n",
        "        }\n",
        "    },\n",
        "    \"LightGBM\": {\n",
        "        \"model\": LGBMClassifier(random_state=42),\n",
        "        \"params\": {\n",
        "            \"n_estimators\": [100, 200],\n",
        "            \"num_leaves\": [31, 50],\n",
        "            \"learning_rate\": [0.1, 0.3]\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# Train and evaluate models\n",
        "for name, config in models.items():\n",
        "    print(f\"\\nTraining {name}...\")\n",
        "    \n",
        "    with mlflow.start_run(run_name=name):\n",
        "        # Log search parameters\n",
        "        search_params = {}\n",
        "        for param_name, param_values in config[\"params\"].items():\n",
        "            # Convert None to \"None\" string and handle other special cases\n",
        "            param_values_str = [str(val) if val is not None else \"None\" for val in param_values]\n",
        "            search_params[f\"search_{param_name}\"] = str(param_values_str)\n",
        "        mlflow.log_params(search_params)\n",
        "        \n",
        "        # Start timer\n",
        "        start_time = time.time()\n",
        "        \n",
        "        # Create and train GridSearchCV\n",
        "        grid_search = GridSearchCV(\n",
        "            config[\"model\"], \n",
        "            config[\"params\"], \n",
        "            cv=3, \n",
        "            scoring=make_scorer(accuracy_score),\n",
        "            n_jobs=-1\n",
        "        )\n",
        "        grid_search.fit(X_train_scaled, y_train)\n",
        "        \n",
        "        # Calculate training time\n",
        "        duration = time.time() - start_time\n",
        "        mlflow.log_metric(\"training_time\", duration)\n",
        "        \n",
        "        # Log best parameters\n",
        "        best_params = {}\n",
        "        for param_name, param_value in grid_search.best_params_.items():\n",
        "            # Convert None to \"None\" string and handle other special cases\n",
        "            best_params[f\"best_{param_name}\"] = str(param_value) if param_value is not None else \"None\"\n",
        "        mlflow.log_params(best_params)\n",
        "        \n",
        "        # Evaluate and log the model\n",
        "        evaluate_and_log_model(\n",
        "            name,\n",
        "            grid_search.best_estimator_,\n",
        "            X_test_scaled,\n",
        "            y_test,\n",
        "            label_encoder\n",
        "        )\n",
        "        \n",
        "        print(f\"Training time: {duration:.2f} seconds\")\n",
        "        print(f\"Best parameters: {grid_search.best_params_}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_and_log_model(model_name, model, X_test, y_test, label_encoder):\n",
        "    \"\"\"\n",
        "    Evaluate the model and log metrics to MLflow (metrics only, no model logging)\n",
        "    \"\"\"\n",
        "    y_pred = model.predict(X_test)\n",
        "    report = classification_report(y_test, y_pred, target_names=label_encoder.classes_, output_dict=True)\n",
        "    try:\n",
        "        for label in label_encoder.classes_:\n",
        "            mlflow.log_metric(f\"{label}_precision\", report[label]['precision'])\n",
        "            mlflow.log_metric(f\"{label}_recall\", report[label]['recall'])\n",
        "            mlflow.log_metric(f\"{label}_f1\", report[label]['f1-score'])\n",
        "        mlflow.log_metric(\"accuracy\", report['accuracy'])\n",
        "        mlflow.log_metric(\"weighted_avg_f1\", report['weighted avg']['f1-score'])\n",
        "    except Exception as e:\n",
        "        print(f\"Warning: Error during metric logging: {str(e)}\")\n",
        "    print(f\"\\nClassification Report for {model_name}:\")\n",
        "    print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYcVXGFv-DdC"
      },
      "source": [
        "Ao fazer uma análise do uso de cada modelo, temos que:\n",
        "\n",
        "Random Forest\n",
        "*   Accuracy: 0.79\n",
        "*   Melhor performance geral (acurácia)\n",
        "\n",
        "XGBoost:\n",
        "*   Accuracy: 0.75\n",
        "\n",
        "LightGBM:\n",
        "*   Accuracy: 0.77\n",
        "\n",
        "Se formos olhar para o recall, temos os seguintes resultados para cada um:\n",
        "\n",
        "Random Forest:\n",
        "*   Good: 0.69\n",
        "*   Poor: 0.80\n",
        "*   Standard: 0.82\n",
        "\n",
        "XGBoost:\n",
        "*   Good: 0.63\n",
        "*   Poor: 0.73\n",
        "*   Standard: 0.81\n",
        "\n",
        "LightGBM:\n",
        "*   Good: 0.65\n",
        "*   Poor: 0.75\n",
        "*   Standard: 0.81\n",
        "\n",
        "Random Forest foi o mais equilibrado entre as três classes, seguido por LightGBM e XGBoost.\n",
        "\n",
        "O tempo de processamento foi bem diferente, sendo o de random forest quase 6x o dos outros dois (9 minutos x 1 minuto e meio).\n",
        "\n",
        "Um recall mais baixo para \"Good\" já era esperado, visto que temos a base desbalanceada, com:\n",
        "\n",
        " Credit_Score:\n",
        " *   Standard: 53174 (53.2%)\n",
        " *   Poor: 28998 (29.0%)\n",
        " *   Good: 17828 (17.8%)\n",
        "\n",
        "Podemos como próximo passo aplicar um Random Forest forçando o algoritmo a compensar o desbalanceamento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMAvVBS1Oz5N",
        "outputId": "f155feb6-6dd1-4371-f1a1-0681b082ae6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Treinando RandomForest...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/08/03 00:36:23 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'a48d7884e8c3465cb38e9842e9c2d35a', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🏃 View run sedate-crow-212 at: https://dagshub.com/fasnis/fiap-ds-mlops-10dtsr-creditscoring-grupo7.mlflow/#/experiments/0/runs/a48d7884e8c3465cb38e9842e9c2d35a\n",
            "🧪 View experiment at: https://dagshub.com/fasnis/fiap-ds-mlops-10dtsr-creditscoring-grupo7.mlflow/#/experiments/0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/08/03 00:38:30 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during sklearn autologging: INTERNAL_ERROR: Response: {'error': 'unsupported endpoint, please contact support@dagshub.com'}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tempo de treinamento para RandomForest: 127.23 segundos\n",
            "Melhores parâmetros: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 200}\n",
            "Relatório de classificação (validação):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Good       0.75      0.74      0.75      3566\n",
            "        Poor       0.78      0.83      0.81      5799\n",
            "    Standard       0.82      0.80      0.81     10635\n",
            "\n",
            "    accuracy                           0.80     20000\n",
            "   macro avg       0.79      0.79      0.79     20000\n",
            "weighted avg       0.80      0.80      0.80     20000\n",
            "\n",
            "Relatório de classificação (validação):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Good       0.75      0.74      0.75      3566\n",
            "        Poor       0.78      0.83      0.81      5799\n",
            "    Standard       0.82      0.80      0.81     10635\n",
            "\n",
            "    accuracy                           0.80     20000\n",
            "   macro avg       0.79      0.79      0.79     20000\n",
            "weighted avg       0.80      0.80      0.80     20000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 1. Create a copy of the dataframes\n",
        "df_pd = df_processed.copy()\n",
        "\n",
        "# 2. Trata strings que viram NaN no Pandas\n",
        "df_pd.replace([\"N/A\", \"NM\", \"na\", \"NaN\", \"-\", \"\"], pd.NA, inplace=True)\n",
        "\n",
        "# 3. Converte colunas para números (menos ID e target)\n",
        "for col in df_pd.columns:\n",
        "    if col not in [\"ID\", \"Customer_ID\", \"Month\", \"Credit_Score\"]:\n",
        "        df_pd[col] = pd.to_numeric(df_pd[col], errors='coerce')\n",
        "\n",
        "# 4. Remove nulos no target e preenche o resto com zero\n",
        "df_pd = df_pd.dropna(subset=[\"Credit_Score\"])\n",
        "# Fill numerical columns with 0, leave 'Credit_Score' as is for encoding\n",
        "numerical_cols_to_fill = df_pd.select_dtypes(include=[\"number\"]).columns.tolist()\n",
        "df_pd[numerical_cols_to_fill] = df_pd[numerical_cols_to_fill].fillna(0)\n",
        "\n",
        "# 5. Seleciona colunas numéricas válidas e o target\n",
        "X = df_pd.drop(columns=[\"Credit_Score\", \"ID\", \"Customer_ID\"])\n",
        "X = X.select_dtypes(include=[\"number\"])\n",
        "y = df_pd[\"Credit_Score\"] # Keep target as is for now\n",
        "\n",
        "# --- Start of added code ---\n",
        "# Encode the target variable\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "# --- End of added code ---\n",
        "\n",
        "# 6. Split e escalonamento (using encoded y)\n",
        "# Use y_encoded for the split\n",
        "X_train, X_val, y_train_encoded, y_val_encoded = train_test_split(X, y_encoded, test_size=0.2, stratify=y_encoded, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "\n",
        "# 7. Modelos e seus grids (no change needed here)\n",
        "models = {\n",
        "    \"RandomForest\": {\n",
        "        \"model\": RandomForestClassifier(class_weight='balanced', random_state=42),\n",
        "        \"params\": {\n",
        "            \"n_estimators\": [100, 200],\n",
        "            \"max_depth\": [None, 10],\n",
        "            \"min_samples_split\": [2, 5]\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# 8. GridSearch, avaliação e predição\n",
        "for name, config in models.items():\n",
        "    print(f\"\\nTreinando {name}...\")\n",
        "    # Cronômetro inicia\n",
        "    start_time = time.time()\n",
        "\n",
        "    gs = GridSearchCV(config[\"model\"], config[\"params\"], cv=3, scoring=\"accuracy\", n_jobs=-1)\n",
        "    # Fit using the encoded training labels\n",
        "    gs.fit(X_train_scaled, y_train_encoded)\n",
        "\n",
        "    end_time = time.time()\n",
        "    duration = end_time - start_time\n",
        "    print(f\"Tempo de treinamento para {name}: {duration:.2f} segundos\")\n",
        "\n",
        "    print(\"Melhores parâmetros:\", gs.best_params_)\n",
        "\n",
        "    # Predict and evaluate using the encoded validation labels\n",
        "    y_val_pred_encoded = gs.best_estimator_.predict(X_val_scaled)\n",
        "    # For classification_report, you can use the encoded labels and target_names\n",
        "    target_names = label_encoder.classes_ # Get original class names\n",
        "    print(\"Relatório de classificação (validação):\")\n",
        "    print(classification_report(y_val_encoded, y_val_pred_encoded, target_names=target_names))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anCZvmH0ffvY"
      },
      "source": [
        "**Aplicação prática**:\n",
        "\n",
        "O modelo pode ser utilizado pela QuantumFinance para:\n",
        "\n",
        "*   Avaliar risco de crédito de novos clientes com base em histórico e comportamento financeiro\n",
        "*   Segmentar clientes por perfil de risco (bom, padrão, ruim)\n",
        "*   Apoiar decisões de concessão de crédito, limite de cartão ou taxas de juros personalizadas\n",
        "*   Antecipar inadimplência, otimizando ações preventivas de cobrança"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Register Best Model\n",
        "After evaluating all models, we'll register the best performing one in MLflow Model Registry."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No completed runs found with accuracy metrics. Please run the model training first.\n"
          ]
        }
      ],
      "source": [
        "# Get all completed runs from the current experiment\n",
        "import time\n",
        "\n",
        "try:\n",
        "    # Get the current experiment\n",
        "    current_experiment = mlflow.get_experiment_by_name(\"Default\")\n",
        "    if current_experiment is None:\n",
        "        current_experiment = mlflow.get_experiment(0)  # Get the default experiment\n",
        "    \n",
        "    # Search only recent runs (last hour) to speed up the search\n",
        "    current_time = int(time.time() * 1000)  # current time in milliseconds\n",
        "    one_hour_ago = current_time - (60 * 60 * 1000)  # one hour ago in milliseconds\n",
        "    \n",
        "    filter_string = f\"metrics.accuracy > 0 AND attributes.start_time > {one_hour_ago}\"\n",
        "    runs = mlflow.search_runs(\n",
        "        experiment_ids=[current_experiment.experiment_id],\n",
        "        filter_string=filter_string,\n",
        "        order_by=[\"metrics.accuracy DESC\"],\n",
        "        max_results=10  # Limit to recent runs\n",
        "    )\n",
        "    \n",
        "    if len(runs) > 0:\n",
        "        # Get the run with highest accuracy\n",
        "        best_run = runs.iloc[0]\n",
        "        best_run_id = best_run.run_id\n",
        "        best_accuracy = best_run[\"metrics.accuracy\"]\n",
        "        \n",
        "        # Register the model\n",
        "        model_name = \"credit-score-classification-model\"\n",
        "        model_version = mlflow.register_model(f\"runs:/{best_run_id}/model\", model_name)\n",
        "        \n",
        "        print(f\"Best model found with accuracy: {best_accuracy:.4f}\")\n",
        "        print(f\"Model registered with name: {model_name}\")\n",
        "        print(f\"Model version: {model_version.version}\")\n",
        "    else:\n",
        "        print(\"No completed runs found with accuracy metrics. Please run the model training first.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error during model registration: {str(e)}\")\n",
        "    print(\"Please ensure MLflow tracking server is accessible and try again.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv (3.13.5)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
