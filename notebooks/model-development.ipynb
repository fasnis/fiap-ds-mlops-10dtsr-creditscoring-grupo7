{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data handling and ML imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, make_scorer, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# MLflow and DagsHub imports\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.xgboost\n",
    "import mlflow.lightgbm\n",
    "import dagshub\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set MLflow tracking URI to a valid local path for macOS (uncomment if you want local tracking)\n",
    "\n",
    "# mlflow.set_tracking_uri(\"file:///tmp/mlruns\")\n",
    "\n",
    "\n",
    "# If using DagsHub, make sure dagshub.init(..., mlflow=True) is called and do not set a local tracking URI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Processed Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLflow and DagsHub Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"fasnis/fiap-ds-mlops-10dtsr-creditscoring-grupo7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"fasnis/fiap-ds-mlops-10dtsr-creditscoring-grupo7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository fasnis/fiap-ds-mlops-10dtsr-creditscoring-grupo7 initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository fasnis/fiap-ds-mlops-10dtsr-creditscoring-grupo7 initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/03 12:45:22 INFO mlflow.tracking.fluent: Autologging successfully enabled for lightgbm.\n",
      "2025/08/03 12:45:22 WARNING mlflow.utils.autologging_utils: MLflow sklearn autologging is known to be compatible with 1.3.0 <= scikit-learn <= 1.7.0, but the installed version is 1.7.1. If you encounter errors during autologging, try upgrading / downgrading scikit-learn to a compatible version, or try upgrading MLflow.\n",
      "2025/08/03 12:45:22 WARNING mlflow.utils.autologging_utils: MLflow sklearn autologging is known to be compatible with 1.3.0 <= scikit-learn <= 1.7.0, but the installed version is 1.7.1. If you encounter errors during autologging, try upgrading / downgrading scikit-learn to a compatible version, or try upgrading MLflow.\n",
      "2025/08/03 12:45:22 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "2025/08/03 12:45:22 WARNING mlflow.utils.autologging_utils: MLflow xgboost autologging is known to be compatible with 1.7.6 <= xgboost <= 3.0.2, but the installed version is 3.0.3. If you encounter errors during autologging, try upgrading / downgrading xgboost to a compatible version, or try upgrading MLflow.\n",
      "2025/08/03 12:45:22 INFO mlflow.tracking.fluent: Autologging successfully enabled for xgboost.\n",
      "2025/08/03 12:45:22 WARNING mlflow.spark: With Pyspark >= 3.2, PYSPARK_PIN_THREAD environment variable must be set to false for Spark datasource autologging to work.\n",
      "2025/08/03 12:45:22 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.\n",
      "2025/08/03 12:45:22 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "2025/08/03 12:45:22 WARNING mlflow.utils.autologging_utils: MLflow xgboost autologging is known to be compatible with 1.7.6 <= xgboost <= 3.0.2, but the installed version is 3.0.3. If you encounter errors during autologging, try upgrading / downgrading xgboost to a compatible version, or try upgrading MLflow.\n",
      "2025/08/03 12:45:22 INFO mlflow.tracking.fluent: Autologging successfully enabled for xgboost.\n",
      "2025/08/03 12:45:22 WARNING mlflow.spark: With Pyspark >= 3.2, PYSPARK_PIN_THREAD environment variable must be set to false for Spark datasource autologging to work.\n",
      "2025/08/03 12:45:22 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow tracking initialized successfully\n"
     ]
    }
   ],
   "source": [
    "# Initialize DagsHub connection and MLflow tracking\n",
    "dagshub.init(repo_owner=\"fasnis\", repo_name=\"fiap-ds-mlops-10dtsr-creditscoring-grupo7\", mlflow=True)\n",
    "\n",
    "# Enable MLflow autologging\n",
    "mlflow.autolog()\n",
    "\n",
    "print(\"MLflow tracking initialized successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (100000, 44)\n",
      "\n",
      "Dataset info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 44 columns):\n",
      " #   Column                                              Non-Null Count   Dtype  \n",
      "---  ------                                              --------------   -----  \n",
      " 0   ID                                                  100000 non-null  object \n",
      " 1   Customer_ID                                         100000 non-null  object \n",
      " 2   Age                                                 97224 non-null   float64\n",
      " 3   Annual_Income                                       100000 non-null  float64\n",
      " 4   Monthly_Inhand_Salary                               100000 non-null  float64\n",
      " 5   Num_Bank_Accounts                                   100000 non-null  int64  \n",
      " 6   Num_Credit_Card                                     100000 non-null  int64  \n",
      " 7   Interest_Rate                                       100000 non-null  int64  \n",
      " 8   Num_of_Loan                                         100000 non-null  int64  \n",
      " 9   Delay_from_due_date                                 100000 non-null  int64  \n",
      " 10  Num_of_Delayed_Payment                              92998 non-null   float64\n",
      " 11  Changed_Credit_Limit                                97909 non-null   float64\n",
      " 12  Num_Credit_Inquiries                                98035 non-null   float64\n",
      " 13  Outstanding_Debt                                    100000 non-null  object \n",
      " 14  Credit_Utilization_Ratio                            100000 non-null  float64\n",
      " 15  Total_EMI_per_month                                 100000 non-null  float64\n",
      " 16  Amount_invested_monthly                             95521 non-null   float64\n",
      " 17  Monthly_Balance                                     98800 non-null   float64\n",
      " 18  Credit_Score                                        100000 non-null  object \n",
      " 19  Credit_History_Age_Months                           90970 non-null   float64\n",
      " 20  Occupation_idx                                      100000 non-null  int64  \n",
      " 21  Type_of_Loan_idx                                    100000 non-null  int64  \n",
      " 22  Credit_Mix_Bad                                      100000 non-null  bool   \n",
      " 23  Credit_Mix_Good                                     100000 non-null  bool   \n",
      " 24  Credit_Mix_N/A                                      100000 non-null  bool   \n",
      " 25  Credit_Mix_Standard                                 100000 non-null  bool   \n",
      " 26  Payment_of_Min_Amount_NM                            100000 non-null  bool   \n",
      " 27  Payment_of_Min_Amount_No                            100000 non-null  bool   \n",
      " 28  Payment_of_Min_Amount_Yes                           100000 non-null  bool   \n",
      " 29  Payment_Behaviour_High_spent_Large_value_payments   100000 non-null  bool   \n",
      " 30  Payment_Behaviour_High_spent_Medium_value_payments  100000 non-null  bool   \n",
      " 31  Payment_Behaviour_High_spent_Small_value_payments   100000 non-null  bool   \n",
      " 32  Payment_Behaviour_Low_spent_Large_value_payments    100000 non-null  bool   \n",
      " 33  Payment_Behaviour_Low_spent_Medium_value_payments   100000 non-null  bool   \n",
      " 34  Payment_Behaviour_Low_spent_Small_value_payments    100000 non-null  bool   \n",
      " 35  Payment_Behaviour_N/A                               100000 non-null  bool   \n",
      " 36  Month_April                                         100000 non-null  bool   \n",
      " 37  Month_August                                        100000 non-null  bool   \n",
      " 38  Month_February                                      100000 non-null  bool   \n",
      " 39  Month_January                                       100000 non-null  bool   \n",
      " 40  Month_July                                          100000 non-null  bool   \n",
      " 41  Month_June                                          100000 non-null  bool   \n",
      " 42  Month_March                                         100000 non-null  bool   \n",
      " 43  Month_May                                           100000 non-null  bool   \n",
      "dtypes: bool(22), float64(11), int64(7), object(4)\n",
      "memory usage: 18.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# Read the processed dataset from local file\n",
    "df_processed = pd.read_csv('../data/processed/creditscore_data_processed.csv')\n",
    "print(\"Dataset shape:\", df_processed.shape)\n",
    "print(\"\\nDataset info:\")\n",
    "df_processed.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "adEubURa0-3R"
   },
   "source": [
    "# Machine Learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LR2_ll40Gj0n"
   },
   "source": [
    "Agora, após fazer uma análise exploratória dos dados e transformá-los conforme necessidade, podemos ir para os modelos de classificação.\n",
    "Vamos trabalhar com três: RandomForest, XGBoost, LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_log_model(model_name, model, X_test, y_test, label_encoder):\n",
    "    \"\"\"\n",
    "    Evaluate the model and log metrics to MLflow (metrics only, no model logging)\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    report = classification_report(y_test, y_pred, target_names=label_encoder.classes_, output_dict=True)\n",
    "    try:\n",
    "        for label in label_encoder.classes_:\n",
    "            mlflow.log_metric(f\"{label}_precision\", report[label]['precision'])\n",
    "            mlflow.log_metric(f\"{label}_recall\", report[label]['recall'])\n",
    "            mlflow.log_metric(f\"{label}_f1\", report[label]['f1-score'])\n",
    "        mlflow.log_metric(\"accuracy\", report['accuracy'])\n",
    "        mlflow.log_metric(\"weighted_avg_f1\", report['weighted avg']['f1-score'])\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Error during metric logging: {str(e)}\")\n",
    "    print(f\"\\nClassification Report for {model_name}:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HAvXu0nC-Dvm",
    "outputId": "e069ce0d-d971-46b4-f85e-383a6541f8b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training RandomForest...\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 30] Read-only file system: '/C:'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 58\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, config \u001b[38;5;129;01min\u001b[39;00m models.items():\n\u001b[32m     56\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mTraining \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mmlflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m     59\u001b[39m         \u001b[38;5;66;03m# Log search parameters\u001b[39;00m\n\u001b[32m     60\u001b[39m         search_params = {}\n\u001b[32m     61\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m param_name, param_values \u001b[38;5;129;01min\u001b[39;00m config[\u001b[33m\"\u001b[39m\u001b[33mparams\u001b[39m\u001b[33m\"\u001b[39m].items():\n\u001b[32m     62\u001b[39m             \u001b[38;5;66;03m# Convert None to \"None\" string and handle other special cases\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-Personal/Educação/FIAP/MBA - DATA SCIENCE AI/MLOPS/TrabalhoIntegrado/fiap-ds-mlops-10dtsr-creditscoring-grupo7/.venv/lib/python3.13/site-packages/mlflow/tracking/fluent.py:386\u001b[39m, in \u001b[36mstart_run\u001b[39m\u001b[34m(run_id, experiment_id, run_name, nested, parent_run_id, tags, description, log_system_metrics)\u001b[39m\n\u001b[32m    378\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(active_run_stack) > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m nested:\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[32m    380\u001b[39m         (\n\u001b[32m    381\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mRun with UUID \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m is already active. To start a new run, first end the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    384\u001b[39m         ).format(active_run_stack[\u001b[32m0\u001b[39m].info.run_id)\n\u001b[32m    385\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m386\u001b[39m client = \u001b[43mMlflowClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run_id:\n\u001b[32m    388\u001b[39m     existing_run_id = run_id\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-Personal/Educação/FIAP/MBA - DATA SCIENCE AI/MLOPS/TrabalhoIntegrado/fiap-ds-mlops-10dtsr-creditscoring-grupo7/.venv/lib/python3.13/site-packages/mlflow/tracking/client.py:174\u001b[39m, in \u001b[36mMlflowClient.__init__\u001b[39m\u001b[34m(self, tracking_uri, registry_uri)\u001b[39m\n\u001b[32m    172\u001b[39m final_tracking_uri = utils._resolve_tracking_uri(tracking_uri)\n\u001b[32m    173\u001b[39m \u001b[38;5;28mself\u001b[39m._registry_uri = registry_utils._resolve_registry_uri(registry_uri, tracking_uri)\n\u001b[32m--> \u001b[39m\u001b[32m174\u001b[39m \u001b[38;5;28mself\u001b[39m._tracking_client = \u001b[43mTrackingServiceClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfinal_tracking_uri\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[38;5;28mself\u001b[39m._tracing_client = TracingClient(tracking_uri)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-Personal/Educação/FIAP/MBA - DATA SCIENCE AI/MLOPS/TrabalhoIntegrado/fiap-ds-mlops-10dtsr-creditscoring-grupo7/.venv/lib/python3.13/site-packages/mlflow/tracking/_tracking_service/client.py:75\u001b[39m, in \u001b[36mTrackingServiceClient.__init__\u001b[39m\u001b[34m(self, tracking_uri)\u001b[39m\n\u001b[32m     70\u001b[39m \u001b[38;5;28mself\u001b[39m.tracking_uri = tracking_uri\n\u001b[32m     71\u001b[39m \u001b[38;5;66;03m# NB: Fetch the tracking store (`self.store`) upon client initialization to ensure that\u001b[39;00m\n\u001b[32m     72\u001b[39m \u001b[38;5;66;03m# the tracking URI is valid and the store can be properly resolved. We define `store` as a\u001b[39;00m\n\u001b[32m     73\u001b[39m \u001b[38;5;66;03m# property method to ensure that the client is serializable, even if the store is not\u001b[39;00m\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# self.store\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstore\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-Personal/Educação/FIAP/MBA - DATA SCIENCE AI/MLOPS/TrabalhoIntegrado/fiap-ds-mlops-10dtsr-creditscoring-grupo7/.venv/lib/python3.13/site-packages/mlflow/tracking/_tracking_service/client.py:79\u001b[39m, in \u001b[36mTrackingServiceClient.store\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstore\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mutils\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_store\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtracking_uri\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-Personal/Educação/FIAP/MBA - DATA SCIENCE AI/MLOPS/TrabalhoIntegrado/fiap-ds-mlops-10dtsr-creditscoring-grupo7/.venv/lib/python3.13/site-packages/mlflow/tracking/_tracking_service/utils.py:211\u001b[39m, in \u001b[36m_get_store\u001b[39m\u001b[34m(store_uri, artifact_uri)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_store\u001b[39m(store_uri=\u001b[38;5;28;01mNone\u001b[39;00m, artifact_uri=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m211\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_tracking_store_registry\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_store\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstore_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_uri\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-Personal/Educação/FIAP/MBA - DATA SCIENCE AI/MLOPS/TrabalhoIntegrado/fiap-ds-mlops-10dtsr-creditscoring-grupo7/.venv/lib/python3.13/site-packages/mlflow/tracking/_tracking_service/registry.py:45\u001b[39m, in \u001b[36mTrackingStoreRegistry.get_store\u001b[39m\u001b[34m(self, store_uri, artifact_uri)\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtracking\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_tracking_service\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m utils\n\u001b[32m     44\u001b[39m resolved_store_uri = utils._resolve_tracking_uri(store_uri)\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_store_with_resolved_uri\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresolved_store_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_uri\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-Personal/Educação/FIAP/MBA - DATA SCIENCE AI/MLOPS/TrabalhoIntegrado/fiap-ds-mlops-10dtsr-creditscoring-grupo7/.venv/lib/python3.13/site-packages/mlflow/tracking/_tracking_service/registry.py:56\u001b[39m, in \u001b[36mTrackingStoreRegistry._get_store_with_resolved_uri\u001b[39m\u001b[34m(self, resolved_store_uri, artifact_uri)\u001b[39m\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _building_store_lock:\n\u001b[32m     55\u001b[39m     builder = \u001b[38;5;28mself\u001b[39m.get_store_builder(resolved_store_uri)\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbuilder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstore_uri\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresolved_store_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_uri\u001b[49m\u001b[43m=\u001b[49m\u001b[43martifact_uri\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-Personal/Educação/FIAP/MBA - DATA SCIENCE AI/MLOPS/TrabalhoIntegrado/fiap-ds-mlops-10dtsr-creditscoring-grupo7/.venv/lib/python3.13/site-packages/mlflow/tracking/_tracking_service/utils.py:135\u001b[39m, in \u001b[36m_get_file_store\u001b[39m\u001b[34m(store_uri, **_)\u001b[39m\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_file_store\u001b[39m(store_uri, **_):\n\u001b[32m    133\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtracking\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfile_store\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FileStore\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFileStore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstore_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore_uri\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-Personal/Educação/FIAP/MBA - DATA SCIENCE AI/MLOPS/TrabalhoIntegrado/fiap-ds-mlops-10dtsr-creditscoring-grupo7/.venv/lib/python3.13/site-packages/mlflow/store/tracking/file_store.py:214\u001b[39m, in \u001b[36mFileStore.__init__\u001b[39m\u001b[34m(self, root_directory, artifact_root_uri)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;66;03m# Create root directory if needed\u001b[39;00m\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m exists(\u001b[38;5;28mself\u001b[39m.root_directory):\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_default_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[38;5;66;03m# Create trash folder if needed\u001b[39;00m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m exists(\u001b[38;5;28mself\u001b[39m.trash_folder):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-Personal/Educação/FIAP/MBA - DATA SCIENCE AI/MLOPS/TrabalhoIntegrado/fiap-ds-mlops-10dtsr-creditscoring-grupo7/.venv/lib/python3.13/site-packages/mlflow/store/tracking/file_store.py:220\u001b[39m, in \u001b[36mFileStore._create_default_experiment\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_create_default_experiment\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m     \u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mroot_directory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m     \u001b[38;5;28mself\u001b[39m._create_experiment_with_id(\n\u001b[32m    222\u001b[39m         name=Experiment.DEFAULT_EXPERIMENT_NAME,\n\u001b[32m    223\u001b[39m         experiment_id=FileStore.DEFAULT_EXPERIMENT_ID,\n\u001b[32m    224\u001b[39m         artifact_uri=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    225\u001b[39m         tags=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    226\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-Personal/Educação/FIAP/MBA - DATA SCIENCE AI/MLOPS/TrabalhoIntegrado/fiap-ds-mlops-10dtsr-creditscoring-grupo7/.venv/lib/python3.13/site-packages/mlflow/utils/file_utils.py:209\u001b[39m, in \u001b[36mmkdir\u001b[39m\u001b[34m(root, name)\u001b[39m\n\u001b[32m    207\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    208\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m e.errno != errno.EEXIST \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.isdir(target):\n\u001b[32m--> \u001b[39m\u001b[32m209\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m target\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-Personal/Educação/FIAP/MBA - DATA SCIENCE AI/MLOPS/TrabalhoIntegrado/fiap-ds-mlops-10dtsr-creditscoring-grupo7/.venv/lib/python3.13/site-packages/mlflow/utils/file_utils.py:206\u001b[39m, in \u001b[36mmkdir\u001b[39m\u001b[34m(root, name)\u001b[39m\n\u001b[32m    204\u001b[39m target = os.path.join(root, name) \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m root\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m     \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    208\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m e.errno != errno.EEXIST \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.isdir(target):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen os>:218\u001b[39m, in \u001b[36mmakedirs\u001b[39m\u001b[34m(name, mode, exist_ok)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen os>:218\u001b[39m, in \u001b[36mmakedirs\u001b[39m\u001b[34m(name, mode, exist_ok)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen os>:228\u001b[39m, in \u001b[36mmakedirs\u001b[39m\u001b[34m(name, mode, exist_ok)\u001b[39m\n",
      "\u001b[31mOSError\u001b[39m: [Errno 30] Read-only file system: '/C:'"
     ]
    }
   ],
   "source": [
    "# Prepare the data\n",
    "X = df_processed.drop(columns=[\"Credit_Score\"])\n",
    "\n",
    "# Convert hexadecimal strings to decimal numbers if any exist\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == 'object':\n",
    "        try:\n",
    "            # Try to convert hex strings to decimal numbers\n",
    "            X[col] = X[col].apply(lambda x: float(int(str(x), 16)) if isinstance(x, str) and '0x' in str(x).lower() else x)\n",
    "        except:\n",
    "            pass  # If conversion fails, leave as is\n",
    "            \n",
    "# Convert remaining strings to numeric, coercing errors to NaN\n",
    "X = X.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Fill NaN values with 0\n",
    "X = X.fillna(0)\n",
    "\n",
    "# Prepare target variable\n",
    "y = df_processed[\"Credit_Score\"]\n",
    "\n",
    "# Encode the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, stratify=y_encoded, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define models with their parameters\n",
    "models = {\n",
    "    \"RandomForest\": {\n",
    "        \"model\": RandomForestClassifier(random_state=42),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [100, 200],\n",
    "            \"max_depth\": [None, 10],\n",
    "            \"min_samples_split\": [2, 5]\n",
    "        }\n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        \"model\": XGBClassifier(eval_metric='mlogloss', random_state=42),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [100, 200],\n",
    "            \"max_depth\": [3, 6],\n",
    "            \"learning_rate\": [0.1, 0.3]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "for name, config in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    \n",
    "    with mlflow.start_run(run_name=name):\n",
    "        # Log search parameters\n",
    "        search_params = {}\n",
    "        for param_name, param_values in config[\"params\"].items():\n",
    "            # Convert None to \"None\" string and handle other special cases\n",
    "            param_values_str = [str(val) if val is not None else \"None\" for val in param_values]\n",
    "            search_params[f\"search_{param_name}\"] = str(param_values_str)\n",
    "        mlflow.log_params(search_params)\n",
    "        \n",
    "        # Start timer\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Create and train GridSearchCV\n",
    "        grid_search = GridSearchCV(\n",
    "            config[\"model\"], \n",
    "            config[\"params\"], \n",
    "            cv=3, \n",
    "            scoring=make_scorer(accuracy_score),\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        grid_search.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        # Calculate training time\n",
    "        duration = time.time() - start_time\n",
    "        mlflow.log_metric(\"training_time\", duration)\n",
    "        \n",
    "        # Log best parameters\n",
    "        best_params = {}\n",
    "        for param_name, param_value in grid_search.best_params_.items():\n",
    "            # Convert None to \"None\" string and handle other special cases\n",
    "            best_params[f\"best_{param_name}\"] = str(param_value) if param_value is not None else \"None\"\n",
    "        mlflow.log_params(best_params)\n",
    "        \n",
    "        # Evaluate and log the model\n",
    "        evaluate_and_log_model(\n",
    "            name,\n",
    "            grid_search.best_estimator_,\n",
    "            X_test_scaled,\n",
    "            y_test,\n",
    "            label_encoder\n",
    "        )\n",
    "        \n",
    "        print(f\"Training time: {duration:.2f} seconds\")\n",
    "        print(f\"Best parameters: {grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dYcVXGFv-DdC"
   },
   "source": [
    "Ao fazer uma análise do uso de cada modelo, temos que:\n",
    "\n",
    "Random Forest\n",
    "*   Accuracy: 0.79\n",
    "*   Melhor performance geral (acurácia)\n",
    "\n",
    "XGBoost:\n",
    "*   Accuracy: 0.75\n",
    "\n",
    "LightGBM:\n",
    "*   Accuracy: 0.77\n",
    "\n",
    "Se formos olhar para o recall, temos os seguintes resultados para cada um:\n",
    "\n",
    "Random Forest:\n",
    "*   Good: 0.69\n",
    "*   Poor: 0.80\n",
    "*   Standard: 0.82\n",
    "\n",
    "XGBoost:\n",
    "*   Good: 0.63\n",
    "*   Poor: 0.73\n",
    "*   Standard: 0.81\n",
    "\n",
    "LightGBM:\n",
    "*   Good: 0.65\n",
    "*   Poor: 0.75\n",
    "*   Standard: 0.81\n",
    "\n",
    "Random Forest foi o mais equilibrado entre as três classes, seguido por LightGBM e XGBoost.\n",
    "\n",
    "O tempo de processamento foi bem diferente, sendo o de random forest quase 6x o dos outros dois (9 minutos x 1 minuto e meio).\n",
    "\n",
    "Um recall mais baixo para \"Good\" já era esperado, visto que temos a base desbalanceada, com:\n",
    "\n",
    " Credit_Score:\n",
    " *   Standard: 53174 (53.2%)\n",
    " *   Poor: 28998 (29.0%)\n",
    " *   Good: 17828 (17.8%)\n",
    "\n",
    "Podemos como próximo passo aplicar um Random Forest forçando o algoritmo a compensar o desbalanceamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fMAvVBS1Oz5N",
    "outputId": "f155feb6-6dd1-4371-f1a1-0681b082ae6c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/03 12:37:23 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'f9932a0e5a2541719ac66ae0e1d13707', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Treinando RandomForest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/03 12:39:11 INFO mlflow.sklearn.utils: Logging the 5 best runs, 3 runs will be omitted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo de treinamento para RandomForest: 108.59 segundos\n",
      "Melhores parâmetros: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Relatório de classificação (validação):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Good       0.76      0.74      0.75      3566\n",
      "        Poor       0.78      0.83      0.81      5799\n",
      "    Standard       0.82      0.80      0.81     10635\n",
      "\n",
      "    accuracy                           0.80     20000\n",
      "   macro avg       0.79      0.79      0.79     20000\n",
      "weighted avg       0.80      0.80      0.80     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Create a copy of the dataframes\n",
    "df_pd = df_processed.copy()\n",
    "\n",
    "# 2. Trata strings que viram NaN no Pandas\n",
    "df_pd.replace([\"N/A\", \"NM\", \"na\", \"NaN\", \"-\", \"\"], pd.NA, inplace=True)\n",
    "\n",
    "# 3. Converte colunas para números (menos ID e target)\n",
    "for col in df_pd.columns:\n",
    "    if col not in [\"ID\", \"Customer_ID\", \"Month\", \"Credit_Score\"]:\n",
    "        df_pd[col] = pd.to_numeric(df_pd[col], errors='coerce')\n",
    "\n",
    "# 4. Remove nulos no target e preenche o resto com zero\n",
    "df_pd = df_pd.dropna(subset=[\"Credit_Score\"])\n",
    "# Fill numerical columns with 0, leave 'Credit_Score' as is for encoding\n",
    "numerical_cols_to_fill = df_pd.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "df_pd[numerical_cols_to_fill] = df_pd[numerical_cols_to_fill].fillna(0)\n",
    "\n",
    "# 5. Seleciona colunas numéricas válidas e o target\n",
    "X = df_pd.drop(columns=[\"Credit_Score\", \"ID\", \"Customer_ID\"])\n",
    "X = X.select_dtypes(include=[\"number\"])\n",
    "y = df_pd[\"Credit_Score\"] # Keep target as is for now\n",
    "\n",
    "# --- Start of added code ---\n",
    "# Encode the target variable\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "# --- End of added code ---\n",
    "\n",
    "# 6. Split e escalonamento (using encoded y)\n",
    "# Use y_encoded for the split\n",
    "X_train, X_val, y_train_encoded, y_val_encoded = train_test_split(X, y_encoded, test_size=0.2, stratify=y_encoded, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# 7. Modelos e seus grids (no change needed here)\n",
    "models = {\n",
    "    \"RandomForest\": {\n",
    "        \"model\": RandomForestClassifier(class_weight='balanced', random_state=42),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [100, 200],\n",
    "            \"max_depth\": [None, 10],\n",
    "            \"min_samples_split\": [2, 5]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# 8. GridSearch, avaliação e predição\n",
    "for name, config in models.items():\n",
    "    print(f\"\\nTreinando {name}...\")\n",
    "    # Cronômetro inicia\n",
    "    start_time = time.time()\n",
    "\n",
    "    gs = GridSearchCV(config[\"model\"], config[\"params\"], cv=3, scoring=\"accuracy\", n_jobs=-1)\n",
    "    # Fit using the encoded training labels\n",
    "    gs.fit(X_train_scaled, y_train_encoded)\n",
    "\n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    print(f\"Tempo de treinamento para {name}: {duration:.2f} segundos\")\n",
    "\n",
    "    print(\"Melhores parâmetros:\", gs.best_params_)\n",
    "\n",
    "    # Predict and evaluate using the encoded validation labels\n",
    "    y_val_pred_encoded = gs.best_estimator_.predict(X_val_scaled)\n",
    "    # For classification_report, you can use the encoded labels and target_names\n",
    "    target_names = label_encoder.classes_ # Get original class names\n",
    "    print(\"Relatório de classificação (validação):\")\n",
    "    print(classification_report(y_val_encoded, y_val_pred_encoded, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "anCZvmH0ffvY"
   },
   "source": [
    "**Aplicação prática**:\n",
    "\n",
    "O modelo pode ser utilizado pela QuantumFinance para:\n",
    "\n",
    "*   Avaliar risco de crédito de novos clientes com base em histórico e comportamento financeiro\n",
    "*   Segmentar clientes por perfil de risco (bom, padrão, ruim)\n",
    "*   Apoiar decisões de concessão de crédito, limite de cartão ou taxas de juros personalizadas\n",
    "*   Antecipar inadimplência, otimizando ações preventivas de cobrança"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Register Best Model\n",
    "After evaluating all models, we'll register the best performing one in MLflow Model Registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'credit-score-classification-model' already exists. Creating a new version of this model...\n",
      "2025/08/03 12:39:15 WARNING mlflow.tracking._model_registry.fluent: Run with id 9eeb4c4172dc4952a671f239de124a65 has no artifacts at artifact path 'model', registering model based on models:/m-26f7ae515d134063a5954b29f95e51d1 instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found with accuracy: 0.7936\n",
      "Model registered with name: credit-score-classification-model\n",
      "Model version: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '2' of model 'credit-score-classification-model'.\n"
     ]
    }
   ],
   "source": [
    "# Get all completed runs from the current experiment\n",
    "import time\n",
    "\n",
    "try:\n",
    "    # Get the current experiment\n",
    "    current_experiment = mlflow.get_experiment_by_name(\"Default\")\n",
    "    if current_experiment is None:\n",
    "        current_experiment = mlflow.get_experiment(0)  # Get the default experiment\n",
    "    \n",
    "    # Search only recent runs (last hour) to speed up the search\n",
    "    current_time = int(time.time() * 1000)  # current time in milliseconds\n",
    "    one_hour_ago = current_time - (60 * 60 * 1000)  # one hour ago in milliseconds\n",
    "    \n",
    "    filter_string = f\"metrics.accuracy > 0 AND attributes.start_time > {one_hour_ago}\"\n",
    "    runs = mlflow.search_runs(\n",
    "        experiment_ids=[current_experiment.experiment_id],\n",
    "        filter_string=filter_string,\n",
    "        order_by=[\"metrics.accuracy DESC\"],\n",
    "        max_results=10  # Limit to recent runs\n",
    "    )\n",
    "    \n",
    "    if len(runs) > 0:\n",
    "        # Get the run with highest accuracy\n",
    "        best_run = runs.iloc[0]\n",
    "        best_run_id = best_run.run_id\n",
    "        best_accuracy = best_run[\"metrics.accuracy\"]\n",
    "        \n",
    "        # Register the model\n",
    "        model_name = \"credit-score-classification-model\"\n",
    "        model_version = mlflow.register_model(f\"runs:/{best_run_id}/model\", model_name)\n",
    "        \n",
    "        print(f\"Best model found with accuracy: {best_accuracy:.4f}\")\n",
    "        print(f\"Model registered with name: {model_name}\")\n",
    "        print(f\"Model version: {model_version.version}\")\n",
    "    else:\n",
    "        print(\"No completed runs found with accuracy metrics. Please run the model training first.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during model registration: {str(e)}\")\n",
    "    print(\"Please ensure MLflow tracking server is accessible and try again.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
