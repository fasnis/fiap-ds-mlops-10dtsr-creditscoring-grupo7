{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data handling and ML imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, make_scorer, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# MLflow and DagsHub imports\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.xgboost\n",
    "import dagshub\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLflow and DagsHub Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"fasnis/fiap-ds-mlops-10dtsr-creditscoring-grupo7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"fasnis/fiap-ds-mlops-10dtsr-creditscoring-grupo7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository fasnis/fiap-ds-mlops-10dtsr-creditscoring-grupo7 initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository fasnis/fiap-ds-mlops-10dtsr-creditscoring-grupo7 initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/03 18:57:19 INFO mlflow.tracking.fluent: Autologging successfully enabled for lightgbm.\n",
      "2025/08/03 18:57:19 WARNING mlflow.utils.autologging_utils: MLflow sklearn autologging is known to be compatible with 0.24.1 <= scikit-learn <= 1.6.1, but the installed version is 1.7.1. If you encounter errors during autologging, try upgrading / downgrading scikit-learn to a compatible version, or try upgrading MLflow.\n",
      "2025/08/03 18:57:19 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "2025/08/03 18:57:19 WARNING mlflow.utils.autologging_utils: MLflow xgboost autologging is known to be compatible with 1.4.2 <= xgboost <= 3.0.0, but the installed version is 3.0.3. If you encounter errors during autologging, try upgrading / downgrading xgboost to a compatible version, or try upgrading MLflow.\n",
      "2025/08/03 18:57:19 INFO mlflow.tracking.fluent: Autologging successfully enabled for xgboost.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow tracking initialized successfully\n"
     ]
    }
   ],
   "source": [
    "# Initialize DagsHub connection and MLflow tracking\n",
    "dagshub.init(repo_owner=\"fasnis\", repo_name=\"fiap-ds-mlops-10dtsr-creditscoring-grupo7\", mlflow=True)\n",
    "\n",
    "# Enable MLflow autologging\n",
    "mlflow.autolog()\n",
    "\n",
    "print(\"MLflow tracking initialized successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (100000, 44)\n",
      "\n",
      "Dataset info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 44 columns):\n",
      " #   Column                                              Non-Null Count   Dtype  \n",
      "---  ------                                              --------------   -----  \n",
      " 0   ID                                                  100000 non-null  object \n",
      " 1   Customer_ID                                         100000 non-null  object \n",
      " 2   Age                                                 97224 non-null   float64\n",
      " 3   Annual_Income                                       100000 non-null  float64\n",
      " 4   Monthly_Inhand_Salary                               100000 non-null  float64\n",
      " 5   Num_Bank_Accounts                                   100000 non-null  int64  \n",
      " 6   Num_Credit_Card                                     100000 non-null  int64  \n",
      " 7   Interest_Rate                                       100000 non-null  int64  \n",
      " 8   Num_of_Loan                                         100000 non-null  int64  \n",
      " 9   Delay_from_due_date                                 100000 non-null  int64  \n",
      " 10  Num_of_Delayed_Payment                              92998 non-null   float64\n",
      " 11  Changed_Credit_Limit                                97909 non-null   float64\n",
      " 12  Num_Credit_Inquiries                                98035 non-null   float64\n",
      " 13  Outstanding_Debt                                    100000 non-null  object \n",
      " 14  Credit_Utilization_Ratio                            100000 non-null  float64\n",
      " 15  Total_EMI_per_month                                 100000 non-null  float64\n",
      " 16  Amount_invested_monthly                             95521 non-null   float64\n",
      " 17  Monthly_Balance                                     98800 non-null   float64\n",
      " 18  Credit_Score                                        100000 non-null  object \n",
      " 19  Credit_History_Age_Months                           90970 non-null   float64\n",
      " 20  Occupation_idx                                      100000 non-null  int64  \n",
      " 21  Type_of_Loan_idx                                    100000 non-null  int64  \n",
      " 22  Credit_Mix_Bad                                      100000 non-null  bool   \n",
      " 23  Credit_Mix_Good                                     100000 non-null  bool   \n",
      " 24  Credit_Mix_N/A                                      100000 non-null  bool   \n",
      " 25  Credit_Mix_Standard                                 100000 non-null  bool   \n",
      " 26  Payment_of_Min_Amount_NM                            100000 non-null  bool   \n",
      " 27  Payment_of_Min_Amount_No                            100000 non-null  bool   \n",
      " 28  Payment_of_Min_Amount_Yes                           100000 non-null  bool   \n",
      " 29  Payment_Behaviour_High_spent_Large_value_payments   100000 non-null  bool   \n",
      " 30  Payment_Behaviour_High_spent_Medium_value_payments  100000 non-null  bool   \n",
      " 31  Payment_Behaviour_High_spent_Small_value_payments   100000 non-null  bool   \n",
      " 32  Payment_Behaviour_Low_spent_Large_value_payments    100000 non-null  bool   \n",
      " 33  Payment_Behaviour_Low_spent_Medium_value_payments   100000 non-null  bool   \n",
      " 34  Payment_Behaviour_Low_spent_Small_value_payments    100000 non-null  bool   \n",
      " 35  Payment_Behaviour_N/A                               100000 non-null  bool   \n",
      " 36  Month_April                                         100000 non-null  bool   \n",
      " 37  Month_August                                        100000 non-null  bool   \n",
      " 38  Month_February                                      100000 non-null  bool   \n",
      " 39  Month_January                                       100000 non-null  bool   \n",
      " 40  Month_July                                          100000 non-null  bool   \n",
      " 41  Month_June                                          100000 non-null  bool   \n",
      " 42  Month_March                                         100000 non-null  bool   \n",
      " 43  Month_May                                           100000 non-null  bool   \n",
      "dtypes: bool(22), float64(11), int64(7), object(4)\n",
      "memory usage: 18.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# Read the processed dataset from local file\n",
    "df_processed = pd.read_csv('../data/processed/creditscore_data_processed.csv')\n",
    "print(\"Dataset shape:\", df_processed.shape)\n",
    "print(\"\\nDataset info:\")\n",
    "df_processed.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "adEubURa0-3R"
   },
   "source": [
    "# Machine Learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_log_model(model_name, model, X_test, y_test, label_encoder):\n",
    "    \"\"\"\n",
    "    Evaluate the model and log metrics to MLflow (metrics only, no model logging)\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    report = classification_report(y_test, y_pred, target_names=label_encoder.classes_, output_dict=True)\n",
    "    try:\n",
    "        for label in label_encoder.classes_:\n",
    "            mlflow.log_metric(f\"{label}_precision\", report[label]['precision'])\n",
    "            mlflow.log_metric(f\"{label}_recall\", report[label]['recall'])\n",
    "            mlflow.log_metric(f\"{label}_f1\", report[label]['f1-score'])\n",
    "        mlflow.log_metric(\"accuracy\", report['accuracy'])\n",
    "        mlflow.log_metric(\"weighted_avg_f1\", report['weighted avg']['f1-score'])\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Error during metric logging: {str(e)}\")\n",
    "    print(f\"\\nClassification Report for {model_name}:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HAvXu0nC-Dvm",
    "outputId": "e069ce0d-d971-46b4-f85e-383a6541f8b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training RandomForest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(81975) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(82000) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "2025/08/03 19:01:01 INFO mlflow.sklearn.utils: Logging the 5 best runs, 3 runs will be omitted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report for RandomForest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Good       0.75      0.73      0.74      3566\n",
      "        Poor       0.78      0.80      0.79      5799\n",
      "    Standard       0.82      0.81      0.81     10635\n",
      "\n",
      "    accuracy                           0.79     20000\n",
      "   macro avg       0.78      0.78      0.78     20000\n",
      "weighted avg       0.79      0.79      0.79     20000\n",
      "\n",
      "Training time: 222.10 seconds\n",
      "Best parameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "ðŸƒ View run RandomForest at: https://dagshub.com/fasnis/fiap-ds-mlops-10dtsr-creditscoring-grupo7.mlflow/#/experiments/0/runs/39bfd1efd65a48a2ae53688f5a70527c\n",
      "ðŸ§ª View experiment at: https://dagshub.com/fasnis/fiap-ds-mlops-10dtsr-creditscoring-grupo7.mlflow/#/experiments/0\n",
      "\n",
      "Training XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(82065) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(82070) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "2025/08/03 19:01:59 INFO mlflow.sklearn.utils: Logging the 5 best runs, 3 runs will be omitted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report for XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Good       0.73      0.74      0.73      3566\n",
      "        Poor       0.78      0.78      0.78      5799\n",
      "    Standard       0.81      0.81      0.81     10635\n",
      "\n",
      "    accuracy                           0.79     20000\n",
      "   macro avg       0.77      0.77      0.77     20000\n",
      "weighted avg       0.79      0.79      0.79     20000\n",
      "\n",
      "Training time: 44.37 seconds\n",
      "Best parameters: {'learning_rate': 0.3, 'max_depth': 6, 'n_estimators': 200}\n",
      "ðŸƒ View run XGBoost at: https://dagshub.com/fasnis/fiap-ds-mlops-10dtsr-creditscoring-grupo7.mlflow/#/experiments/0/runs/66bee58e67ee46e6b43c533b8168f130\n",
      "ðŸ§ª View experiment at: https://dagshub.com/fasnis/fiap-ds-mlops-10dtsr-creditscoring-grupo7.mlflow/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "# Prepare the data\n",
    "X = df_processed.drop(columns=[\"Credit_Score\"])\n",
    "\n",
    "# Convert hexadecimal strings to decimal numbers if any exist\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == 'object':\n",
    "        try:\n",
    "            # Try to convert hex strings to decimal numbers\n",
    "            X[col] = X[col].apply(lambda x: float(int(str(x), 16)) if isinstance(x, str) and '0x' in str(x).lower() else x)\n",
    "        except:\n",
    "            pass  # If conversion fails, leave as is\n",
    "            \n",
    "# Convert remaining strings to numeric, coercing errors to NaN\n",
    "X = X.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Fill NaN values with 0\n",
    "X = X.fillna(0)\n",
    "\n",
    "# Prepare target variable\n",
    "y = df_processed[\"Credit_Score\"]\n",
    "\n",
    "# Encode the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, stratify=y_encoded, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define models with their parameters\n",
    "models = {\n",
    "    \"RandomForest\": {\n",
    "        \"model\": RandomForestClassifier(random_state=42),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [100, 200],\n",
    "            \"max_depth\": [None, 10],\n",
    "            \"min_samples_split\": [2, 5]\n",
    "        }\n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        \"model\": XGBClassifier(eval_metric='mlogloss', random_state=42),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [100, 200],\n",
    "            \"max_depth\": [3, 6],\n",
    "            \"learning_rate\": [0.1, 0.3]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "for name, config in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    \n",
    "    with mlflow.start_run(run_name=name):\n",
    "        # Log search parameters\n",
    "        search_params = {}\n",
    "        for param_name, param_values in config[\"params\"].items():\n",
    "            # Convert None to \"None\" string and handle other special cases\n",
    "            param_values_str = [str(val) if val is not None else \"None\" for val in param_values]\n",
    "            search_params[f\"search_{param_name}\"] = str(param_values_str)\n",
    "        mlflow.log_params(search_params)\n",
    "        \n",
    "        # Start timer\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Create and train GridSearchCV\n",
    "        grid_search = GridSearchCV(\n",
    "            config[\"model\"], \n",
    "            config[\"params\"], \n",
    "            cv=3, \n",
    "            scoring=make_scorer(accuracy_score),\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        grid_search.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        # Calculate training time\n",
    "        duration = time.time() - start_time\n",
    "        mlflow.log_metric(\"training_time\", duration)\n",
    "        \n",
    "        # Log best parameters\n",
    "        best_params = {}\n",
    "        for param_name, param_value in grid_search.best_params_.items():\n",
    "            # Convert None to \"None\" string and handle other special cases\n",
    "            best_params[f\"best_{param_name}\"] = str(param_value) if param_value is not None else \"None\"\n",
    "        mlflow.log_params(best_params)\n",
    "        \n",
    "        # Evaluate and log the model\n",
    "        evaluate_and_log_model(\n",
    "            name,\n",
    "            grid_search.best_estimator_,\n",
    "            X_test_scaled,\n",
    "            y_test,\n",
    "            label_encoder\n",
    "        )\n",
    "        \n",
    "        print(f\"Training time: {duration:.2f} seconds\")\n",
    "        print(f\"Best parameters: {grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Register Best Model\n",
    "After evaluating all models, we'll register the best performing one in MLflow Model Registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'credit-score-classification-model' already exists. Creating a new version of this model...\n",
      "2025/08/03 19:02:46 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: credit-score-classification-model, version 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found with accuracy: 0.7941\n",
      "Model registered with name: credit-score-classification-model\n",
      "Model version: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '2' of model 'credit-score-classification-model'.\n"
     ]
    }
   ],
   "source": [
    "# Get all completed runs from the current experiment\n",
    "import time\n",
    "\n",
    "try:\n",
    "    # Get the current experiment\n",
    "    current_experiment = mlflow.get_experiment_by_name(\"Default\")\n",
    "    if current_experiment is None:\n",
    "        current_experiment = mlflow.get_experiment(0)  # Get the default experiment\n",
    "    \n",
    "    # Search only recent runs (last hour) to speed up the search\n",
    "    current_time = int(time.time() * 1000)  # current time in milliseconds\n",
    "    one_hour_ago = current_time - (60 * 60 * 1000)  # one hour ago in milliseconds\n",
    "    \n",
    "    filter_string = f\"metrics.accuracy > 0 AND attributes.start_time > {one_hour_ago}\"\n",
    "    runs = mlflow.search_runs(\n",
    "        experiment_ids=[current_experiment.experiment_id],\n",
    "        filter_string=filter_string,\n",
    "        order_by=[\"metrics.accuracy DESC\"],\n",
    "        max_results=10  # Limit to recent runs\n",
    "    )\n",
    "    \n",
    "    if len(runs) > 0:\n",
    "        # Get the run with highest accuracy\n",
    "        best_run = runs.iloc[0]\n",
    "        best_run_id = best_run.run_id\n",
    "        best_accuracy = best_run[\"metrics.accuracy\"]\n",
    "        \n",
    "        # Register the model\n",
    "        model_name = \"credit-score-classification-model\"\n",
    "        model_version = mlflow.register_model(f\"runs:/{best_run_id}/model\", model_name)\n",
    "        \n",
    "        print(f\"Best model found with accuracy: {best_accuracy:.4f}\")\n",
    "        print(f\"Model registered with name: {model_name}\")\n",
    "        print(f\"Model version: {model_version.version}\")\n",
    "    else:\n",
    "        print(\"No completed runs found with accuracy metrics. Please run the model training first.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during model registration: {str(e)}\")\n",
    "    print(\"Please ensure MLflow tracking server is accessible and try again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading latest version of Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:09<00:00,  9.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ../models/model.pkl\n",
      "Metadata saved to ../models/model_metadata.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# 1. Caminho relativo para salvar em ../models/\n",
    "models_dir = \"../models\"\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "# 2. Nome do modelo e cliente MLflow\n",
    "model_name = \"credit-score-classification-model\"\n",
    "client = MlflowClient()\n",
    "\n",
    "# 3. Obter a versÃ£o mais recente registrada\n",
    "registered_versions = sorted(\n",
    "    client.search_model_versions(f\"name='{model_name}'\"),\n",
    "    key=lambda v: int(v.version),\n",
    "    reverse=True\n",
    ")\n",
    "\n",
    "if not registered_versions:\n",
    "    raise ValueError(f\"No registered versions found for model '{model_name}'\")\n",
    "\n",
    "latest = registered_versions[0]\n",
    "\n",
    "# 4. Caminho fixo do artifact\n",
    "artifact_path = \"model/model.pkl\"\n",
    "\n",
    "# 5. Baixar diretamente o model.pkl\n",
    "downloaded_file_path = client.download_artifacts(\n",
    "    run_id=latest.run_id,\n",
    "    path=artifact_path\n",
    ")\n",
    "\n",
    "final_model_path = os.path.join(models_dir, \"model.pkl\")\n",
    "with open(downloaded_file_path, \"rb\") as src, open(final_model_path, \"wb\") as dst:\n",
    "    dst.write(src.read())\n",
    "\n",
    "print(f\"Model saved to {final_model_path}\")\n",
    "\n",
    "# 6. Salvar metadata\n",
    "model_metadata = {\n",
    "    \"model_name\": model_name,\n",
    "    \"version\": latest.version,\n",
    "    \"run_id\": latest.run_id,\n",
    "    \"source\": latest.source,\n",
    "    \"downloaded_at\": datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "metadata_path = os.path.join(models_dir, \"model_metadata.json\")\n",
    "with open(metadata_path, \"w\") as f:\n",
    "    json.dump(model_metadata, f, indent=2)\n",
    "\n",
    "print(f\"Metadata saved to {metadata_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
