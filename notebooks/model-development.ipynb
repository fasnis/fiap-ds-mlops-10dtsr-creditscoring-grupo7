{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adEubURa0-3R"
      },
      "source": [
        "# Machine Learning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LR2_ll40Gj0n"
      },
      "source": [
        "Agora, após fazer uma análise exploratória dos dados e transformá-los conforme necessidade, podemos ir para os modelos de classificação.\n",
        "Vamos trabalhar com três: RandomForest, XGBoost, LightGBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAvXu0nC-Dvm",
        "outputId": "e069ce0d-d971-46b4-f85e-383a6541f8b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Treinando RandomForest...\n",
            "Tempo de treinamento para RandomForest: 509.65 segundos\n",
            "Melhores parâmetros: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
            "Relatório de classificação (validação):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Good       0.77      0.69      0.73      3566\n",
            "        Poor       0.79      0.80      0.80      5799\n",
            "    Standard       0.80      0.82      0.81     10635\n",
            "\n",
            "    accuracy                           0.79     20000\n",
            "   macro avg       0.79      0.77      0.78     20000\n",
            "weighted avg       0.79      0.79      0.79     20000\n",
            "\n",
            "Predições no conjunto externo:\n",
            "Standard    27711\n",
            "Poor        14393\n",
            "Good         7896\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Treinando XGBoost...\n",
            "Tempo de treinamento para XGBoost: 97.26 segundos\n",
            "Melhores parâmetros: {'learning_rate': 0.3, 'max_depth': 6, 'n_estimators': 200}\n",
            "Relatório de classificação (validação):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Good       0.72      0.63      0.67      3566\n",
            "        Poor       0.76      0.73      0.75      5799\n",
            "    Standard       0.76      0.81      0.78     10635\n",
            "\n",
            "    accuracy                           0.75     20000\n",
            "   macro avg       0.75      0.72      0.73     20000\n",
            "weighted avg       0.75      0.75      0.75     20000\n",
            "\n",
            "Predições no conjunto externo:\n",
            "Standard    28137\n",
            "Poor        13887\n",
            "Good         7976\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Treinando LightGBM...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006861 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1982\n",
            "[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score -1.724428\n",
            "[LightGBM] [Info] Start training from score -1.237917\n",
            "[LightGBM] [Info] Start training from score -0.631605\n",
            "Tempo de treinamento para LightGBM: 88.25 segundos\n",
            "Melhores parâmetros: {'learning_rate': 0.3, 'n_estimators': 200, 'num_leaves': 50}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relatório de classificação (validação):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Good       0.74      0.65      0.69      3566\n",
            "        Poor       0.78      0.75      0.76      5799\n",
            "    Standard       0.77      0.81      0.79     10635\n",
            "\n",
            "    accuracy                           0.77     20000\n",
            "   macro avg       0.76      0.74      0.75     20000\n",
            "weighted avg       0.77      0.77      0.77     20000\n",
            "\n",
            "Predições no conjunto externo:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Standard    28073\n",
            "Poor        13885\n",
            "Good         8042\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# 1. Converte de Spark para Pandas\n",
        "df_pd = df_raw.toPandas()\n",
        "df_pd_test = df_test.toPandas()\n",
        "\n",
        "# 2. Trata strings que viram NaN no Pandas\n",
        "for df in [df_pd, df_pd_test]:\n",
        "    df.replace([\"N/A\", \"NM\", \"na\", \"NaN\", \"-\", \"\"], pd.NA, inplace=True)\n",
        "\n",
        "# 3. Converte colunas para números (menos ID e target)\n",
        "for col in df_pd.columns:\n",
        "    if col not in [\"ID\", \"Customer_ID\", \"Month\", \"Credit_Score\"]:\n",
        "        df_pd[col] = pd.to_numeric(df_pd[col], errors='coerce')\n",
        "        if col in df_pd_test.columns:\n",
        "            df_pd_test[col] = pd.to_numeric(df_pd_test[col], errors='coerce')\n",
        "\n",
        "# 4. Remove nulos no target e preenche o resto com zero\n",
        "df_pd = df_pd.dropna(subset=[\"Credit_Score\"])\n",
        "# Fill numerical columns with 0, leave 'Credit_Score' as is for encoding\n",
        "numerical_cols_to_fill = df_pd.select_dtypes(include=[\"number\"]).columns.tolist()\n",
        "df_pd[numerical_cols_to_fill] = df_pd[numerical_cols_to_fill].fillna(0)\n",
        "\n",
        "numerical_cols_test_to_fill = df_pd_test.select_dtypes(include=[\"number\"]).columns.tolist()\n",
        "df_pd_test[numerical_cols_test_to_fill] = df_pd_test[numerical_cols_test_to_fill].fillna(0)\n",
        "\n",
        "\n",
        "# 5. Seleciona colunas numéricas válidas e o target\n",
        "X = df_pd.drop(columns=[\"Credit_Score\", \"ID\", \"Customer_ID\"])\n",
        "X = X.select_dtypes(include=[\"number\"])\n",
        "y = df_pd[\"Credit_Score\"] # Keep target as is for now\n",
        "\n",
        "X_external = df_pd_test.drop(columns=[\"ID\", \"Customer_ID\", \"Credit_Score\"], errors=\"ignore\") # Drop Credit_Score from test if it exists\n",
        "X_external = X_external.select_dtypes(include=[\"number\"])\n",
        "\n",
        "# --- Start of added code ---\n",
        "# Encode the target variable\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "# --- End of added code ---\n",
        "\n",
        "# 6. Split e escalonamento (using encoded y)\n",
        "# Use y_encoded for the split\n",
        "X_train, X_val, y_train_encoded, y_val_encoded = train_test_split(X, y_encoded, test_size=0.2, stratify=y_encoded, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "X_external_scaled = scaler.transform(X_external)\n",
        "\n",
        "# 7. Modelos e seus grids (no change needed here)\n",
        "models = {\n",
        "    \"RandomForest\": {\n",
        "        \"model\": RandomForestClassifier(random_state=42),\n",
        "        \"params\": {\n",
        "            \"n_estimators\": [100, 200],\n",
        "            \"max_depth\": [None, 10],\n",
        "            \"min_samples_split\": [2, 5]\n",
        "        }\n",
        "    },\n",
        "    \"XGBoost\": {\n",
        "        # use_label_encoder is deprecated, eval_metric='logloss' is good\n",
        "        \"model\": XGBClassifier(eval_metric='logloss', random_state=42),\n",
        "        \"params\": {\n",
        "            \"n_estimators\": [100, 200],\n",
        "            \"max_depth\": [3, 6],\n",
        "            \"learning_rate\": [0.1, 0.3]\n",
        "        }\n",
        "    },\n",
        "    \"LightGBM\": {\n",
        "        \"model\": LGBMClassifier(random_state=42),\n",
        "        \"params\": {\n",
        "            \"n_estimators\": [100, 200],\n",
        "            \"num_leaves\": [31, 50],\n",
        "            \"learning_rate\": [0.1, 0.3]\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# 8. GridSearch, avaliação e predição externa (using encoded y)\n",
        "for name, config in models.items():\n",
        "    print(f\"\\nTreinando {name}...\")\n",
        "\n",
        "    # Cronômetro inicia\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Cronômetro inicia\n",
        "    gs = GridSearchCV(config[\"model\"], config[\"params\"], cv=3, scoring=\"accuracy\", n_jobs=-1)\n",
        "    # Fit using the encoded training labels\n",
        "    gs.fit(X_train_scaled, y_train_encoded)\n",
        "\n",
        "    end_time = time.time()\n",
        "    duration = end_time - start_time\n",
        "    print(f\"Tempo de treinamento para {name}: {duration:.2f} segundos\")\n",
        "\n",
        "    print(\"Melhores parâmetros:\", gs.best_params_)\n",
        "\n",
        "    # Predict and evaluate using the encoded validation labels\n",
        "    y_val_pred_encoded = gs.best_estimator_.predict(X_val_scaled)\n",
        "    # Decode predictions back to original labels for classification report if needed, or keep encoded\n",
        "    # For classification_report, you can use the encoded labels and target_names\n",
        "    target_names = label_encoder.classes_ # Get original class names\n",
        "    print(\"Relatório de classificação (validação):\")\n",
        "    print(classification_report(y_val_encoded, y_val_pred_encoded, target_names=target_names))\n",
        "\n",
        "\n",
        "    # Teste externo\n",
        "    print(\"Predições no conjunto externo:\")\n",
        "    y_ext_pred_encoded = gs.best_estimator_.predict(X_external_scaled)\n",
        "    # Decode external predictions if you need the original labels\n",
        "    y_ext_pred = label_encoder.inverse_transform(y_ext_pred_encoded)\n",
        "    print(pd.Series(y_ext_pred).value_counts())\n",
        "\n",
        "    # Avalia se o df_test possui o target real\n",
        "    if \"Credit_Score\" in df_pd_test.columns:\n",
        "        y_ext_real = df_pd_test[\"Credit_Score\"]\n",
        "        # Encode the real external target before comparing\n",
        "        y_ext_real_encoded = label_encoder.transform(y_ext_real)\n",
        "        print(\"Relatório de classificação (dados externos):\")\n",
        "        # Use encoded predictions and encoded real values for classification report\n",
        "        print(classification_report(y_ext_real_encoded, y_ext_pred_encoded, target_names=target_names))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYcVXGFv-DdC"
      },
      "source": [
        "Ao fazer uma análise do uso de cada modelo, temos que:\n",
        "\n",
        "Random Forest\n",
        "*   Accuracy: 0.79\n",
        "*   Melhor performance geral (acurácia)\n",
        "\n",
        "XGBoost:\n",
        "*   Accuracy: 0.75\n",
        "\n",
        "LightGBM:\n",
        "*   Accuracy: 0.77\n",
        "\n",
        "Se formos olhar para o recall, temos os seguintes resultados para cada um:\n",
        "\n",
        "Random Forest:\n",
        "*   Good: 0.69\n",
        "*   Poor: 0.80\n",
        "*   Standard: 0.82\n",
        "\n",
        "XGBoost:\n",
        "*   Good: 0.63\n",
        "*   Poor: 0.73\n",
        "*   Standard: 0.81\n",
        "\n",
        "LightGBM:\n",
        "*   Good: 0.65\n",
        "*   Poor: 0.75\n",
        "*   Standard: 0.81\n",
        "\n",
        "Random Forest foi o mais equilibrado entre as três classes, seguido por LightGBM e XGBoost.\n",
        "\n",
        "O tempo de processamento foi bem diferente, sendo o de random forest quase 6x o dos outros dois (9 minutos x 1 minuto e meio).\n",
        "\n",
        "Um recall mais baixo para \"Good\" já era esperado, visto que temos a base desbalanceada, com:\n",
        "\n",
        " Credit_Score:\n",
        " *   Standard: 53174 (53.2%)\n",
        " *   Poor: 28998 (29.0%)\n",
        " *   Good: 17828 (17.8%)\n",
        "\n",
        "Podemos como próximo passo aplicar um Random Forest forçando o algoritmo a compensar o desbalanceamento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMAvVBS1Oz5N",
        "outputId": "f155feb6-6dd1-4371-f1a1-0681b082ae6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Treinando RandomForest...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tempo de treinamento para RandomForest: 506.93 segundos\n",
            "Melhores parâmetros: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 200}\n",
            "Relatório de classificação (validação):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Good       0.75      0.74      0.75      3566\n",
            "        Poor       0.78      0.82      0.80      5799\n",
            "    Standard       0.81      0.80      0.81     10635\n",
            "\n",
            "    accuracy                           0.79     20000\n",
            "   macro avg       0.78      0.79      0.78     20000\n",
            "weighted avg       0.79      0.79      0.79     20000\n",
            "\n",
            "Predições no conjunto externo:\n",
            "Standard    26609\n",
            "Poor        14778\n",
            "Good         8613\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# 1. Converte de Spark para Pandas\n",
        "df_pd = df_raw.toPandas()\n",
        "df_pd_test = df_test.toPandas()\n",
        "\n",
        "# 2. Trata strings que viram NaN no Pandas\n",
        "for df in [df_pd, df_pd_test]:\n",
        "    df.replace([\"N/A\", \"NM\", \"na\", \"NaN\", \"-\", \"\"], pd.NA, inplace=True)\n",
        "\n",
        "# 3. Converte colunas para números (menos ID e target)\n",
        "for col in df_pd.columns:\n",
        "    if col not in [\"ID\", \"Customer_ID\", \"Month\", \"Credit_Score\"]:\n",
        "        df_pd[col] = pd.to_numeric(df_pd[col], errors='coerce')\n",
        "        if col in df_pd_test.columns:\n",
        "            df_pd_test[col] = pd.to_numeric(df_pd_test[col], errors='coerce')\n",
        "\n",
        "# 4. Remove nulos no target e preenche o resto com zero\n",
        "df_pd = df_pd.dropna(subset=[\"Credit_Score\"])\n",
        "# Fill numerical columns with 0, leave 'Credit_Score' as is for encoding\n",
        "numerical_cols_to_fill = df_pd.select_dtypes(include=[\"number\"]).columns.tolist()\n",
        "df_pd[numerical_cols_to_fill] = df_pd[numerical_cols_to_fill].fillna(0)\n",
        "\n",
        "numerical_cols_test_to_fill = df_pd_test.select_dtypes(include=[\"number\"]).columns.tolist()\n",
        "df_pd_test[numerical_cols_test_to_fill] = df_pd_test[numerical_cols_test_to_fill].fillna(0)\n",
        "\n",
        "\n",
        "# 5. Seleciona colunas numéricas válidas e o target\n",
        "X = df_pd.drop(columns=[\"Credit_Score\", \"ID\", \"Customer_ID\"])\n",
        "X = X.select_dtypes(include=[\"number\"])\n",
        "y = df_pd[\"Credit_Score\"] # Keep target as is for now\n",
        "\n",
        "X_external = df_pd_test.drop(columns=[\"ID\", \"Customer_ID\", \"Credit_Score\"], errors=\"ignore\") # Drop Credit_Score from test if it exists\n",
        "X_external = X_external.select_dtypes(include=[\"number\"])\n",
        "\n",
        "# --- Start of added code ---\n",
        "# Encode the target variable\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "# --- End of added code ---\n",
        "\n",
        "# 6. Split e escalonamento (using encoded y)\n",
        "# Use y_encoded for the split\n",
        "X_train, X_val, y_train_encoded, y_val_encoded = train_test_split(X, y_encoded, test_size=0.2, stratify=y_encoded, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "X_external_scaled = scaler.transform(X_external)\n",
        "\n",
        "# 7. Modelos e seus grids (no change needed here)\n",
        "models = {\n",
        "    \"RandomForest\": {\n",
        "        \"model\": RandomForestClassifier(class_weight='balanced', random_state=42),\n",
        "        \"params\": {\n",
        "            \"n_estimators\": [100, 200],\n",
        "            \"max_depth\": [None, 10],\n",
        "            \"min_samples_split\": [2, 5]\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# 8. GridSearch, avaliação e predição externa (using encoded y)\n",
        "for name, config in models.items():\n",
        "    print(f\"\\nTreinando {name}...\")\n",
        "    # Cronômetro inicia\n",
        "    start_time = time.time()\n",
        "\n",
        "    gs = GridSearchCV(config[\"model\"], config[\"params\"], cv=3, scoring=\"accuracy\", n_jobs=-1)\n",
        "    # Fit using the encoded training labels\n",
        "    gs.fit(X_train_scaled, y_train_encoded)\n",
        "\n",
        "    end_time = time.time()\n",
        "    duration = end_time - start_time\n",
        "    print(f\"Tempo de treinamento para {name}: {duration:.2f} segundos\")\n",
        "\n",
        "    print(\"Melhores parâmetros:\", gs.best_params_)\n",
        "\n",
        "    # Predict and evaluate using the encoded validation labels\n",
        "    y_val_pred_encoded = gs.best_estimator_.predict(X_val_scaled)\n",
        "    # Decode predictions back to original labels for classification report if needed, or keep encoded\n",
        "    # For classification_report, you can use the encoded labels and target_names\n",
        "    target_names = label_encoder.classes_ # Get original class names\n",
        "    print(\"Relatório de classificação (validação):\")\n",
        "    print(classification_report(y_val_encoded, y_val_pred_encoded, target_names=target_names))\n",
        "\n",
        "\n",
        "    # Teste externo\n",
        "    print(\"Predições no conjunto externo:\")\n",
        "    y_ext_pred_encoded = gs.best_estimator_.predict(X_external_scaled)\n",
        "    # Decode external predictions if you need the original labels\n",
        "    y_ext_pred = label_encoder.inverse_transform(y_ext_pred_encoded)\n",
        "    print(pd.Series(y_ext_pred).value_counts())\n",
        "\n",
        "    # Avalia se o df_test possui o target real\n",
        "    if \"Credit_Score\" in df_pd_test.columns:\n",
        "        y_ext_real = df_pd_test[\"Credit_Score\"]\n",
        "        # Encode the real external target before comparing\n",
        "        y_ext_real_encoded = label_encoder.transform(y_ext_real)\n",
        "        print(\"Relatório de classificação (dados externos):\")\n",
        "        # Use encoded predictions and encoded real values for classification report\n",
        "        print(classification_report(y_ext_real_encoded, y_ext_pred_encoded, target_names=target_names))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anCZvmH0ffvY"
      },
      "source": [
        "**Aplicação prática**:\n",
        "\n",
        "O modelo pode ser utilizado pela QuantumFinance para:\n",
        "\n",
        "*   Avaliar risco de crédito de novos clientes com base em histórico e comportamento financeiro\n",
        "*   Segmentar clientes por perfil de risco (bom, padrão, ruim)\n",
        "*   Apoiar decisões de concessão de crédito, limite de cartão ou taxas de juros personalizadas\n",
        "*   Antecipar inadimplência, otimizando ações preventivas de cobrança"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
